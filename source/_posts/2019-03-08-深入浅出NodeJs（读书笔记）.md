---
title: 深入浅出NodeJs（读书笔记）
tags: [NodeJs, 深入浅出NodeJs]
toc: true
mathjax: true
date: 2019-03-08 13:36:14
categories:
- 编程语言
- NodeJs
---

## 第一章 Node简介

1. 在Node中，绝大多数的操作都是以异步的方式进行调用
2. Node相比于其它大多数后端语言的独特之处：事件驱动、异步、回调函数
3. Node保持了JS在浏览器中单线程的特点。在Node中，JS与其余线程是无法共享任何状态的。单线程的最大好处是不用像多线程那样处处在意状态的同步问题，这里没有死锁的存在，也没有线程上下文交换带来的性能上的开销。单线程的弱点：
    * 无法利用多核CPU
    * 错误会引起整个应用退出，应用的健壮性值得考验
    * 大量计算占用CPU导致无法继续调用异步I/O
4. Node的应用场景：
    * I/O密集型：从单线程的角度来说，Node处理I/O的能力是值得竖起拇指称赞的。通常，说Node擅长I/O密集型的应用场景基本上是没人反对的。Node面向网络且擅长并行I/O，能够有效地组织起更多的硬件资源，从而提供更多好的服务。I/O密集型的优势主要在于Node利用事件循环的处理能力，而不是启动每一个线程为每一个请求服务，资源占用极少
    * CPU密集型：CPU密集型应用给Node带来的挑战主要是：由于JS单线程的原因，如果有长时间运行的计算（比如大循环），将会导致CPU时间片不能释放，使得后续I/O无法发起。但是适当调整和分解大型运算任务为多个小任务，使得运算能够适时释放，不阻塞I/O调用的发起，这样既可以同事享受到并行异步I/O的好处，又能充分利用CPU
5. 身为单线程的应用，Node如何能够充分的利用CPU?
    * Node可以通过编写C/C++扩展的方式更高效地利用CPU，将一些V8不能做到性能极致的地方通过C/C++来实现
    * 通过创建子进程的方式，将一部分Node进程当做常驻服务进程用于计算，然后利用进程间的消息来传递结果，将计算与I/O分离，这样还能充分利用多CPU
6. Node使用者的各自倚重点：
    * 前后端编程语言环境统一
    * Node带来的高性能I/O用于实时应用
    * 并行I/O使得使用者可以更高效的利用分布式环境
    * 并行I/O，有效利用稳定接口提升Web渲染能力
    * 云计算平台提供Node支持
    * 游戏开发领域
    * 工具类应用

## 第二章 模块机制

1. 在Web1.0时代，对于JS自身而言，它的规范是薄弱的，存在以下缺陷：
    * 没有模块系统
    * 标准库较少
    * 没有标准接口
    * 缺乏包管理系统
2. CommonJS规范
    * 模块引用：var mathModule = require('mathModule')
    * 模块导出：exports.add = function (x, y) { return x + y }
3. Node在实现中并非完全按照规范实现，而是对模块规范进行了一定的取舍，在Node中引入模块，需要经历如下3个步骤：
    * 路径分析
    * 文件定位
    * 编译执行
4. 在Node中模块分为两类：
    * 核心模块：核心模块部分在Node源代码的编译过程中，编译进了二进制执行文件。在Node进程启动时，部分核心模块就被直接加载进内存中，所以这部分核心模块引入时，文件定位和编译执行这两个步骤可以省略掉，并且在路径分析中优先判断，所以它的加载速度是最快的
    * 文件模块：是在运行时动态加载，需要完整的路径分析、文件定位、编译执行过程，速度比核心模块慢
5. 与前端浏览器会缓存静态脚本文件以提高性能一样，Node对引入过的模块都会进行缓存，以减少二次引入时的开销。不同的地方在于，浏览器仅仅缓存文件，而Node缓存的是编译和执行之后的对象。
6. 模块标识符分析
    * 模块表示符的分类：
        * 核心模块，如https、fs、path等
        * .或..开始的相对路径文件模块
        * 以/开始的绝对路径文件模块
        * 非路径形式的文件模块，如自定义的connect模块
7. Node模块加载顺序：核心模块 > 文件模块 > 自定义模块（需要按照module.paths路径一层层向上寻找，直到找到目标文件或系统根目录为止）
8. CommonJS模块规范允许在标识符中不包含文件扩展名，这种情况下，Node会按.js、.json、.node的次序补足扩展名，依次尝试。在尝试的过程中，需要调用fs模块同步阻塞式地判断文件是否存在。因为Node是单线程的，所以这里是一个会引起性能问题的地方。小诀窍是：如果是.node和.json文件，在传递给require()的标识符中带上扩展名，会加快一点速度。另一个诀窍是：同步配合缓存，可以大幅度缓解Node单线程中阻塞式调用的缺陷。
9. 模块编译，每一个编译成功的模块都会将其文件路径作为索引缓存在Module._cache对象上

    ```javascript
    // 在Node中，每个文件模块都是一个对象，它的定义如下
    function Module(id, parent) {
        this.id = id
        this.exports = {}
        this.parent = parent
        if (parent && parent.children) {
            parent.children.push(this)
        }

        this.filename = null
        this.loaded = false
        this.children = []
    }
    ```

    对于不同的文件扩展名，模块载入的方法也有所不同
    * .js文件：通过fs模块同步读取文件后编译执行
    * .node文件：这是用C/C++编写的扩展文件，通过dlopen()方法加载最后编译生成的文件
    * .json文件：通过fs模块同步读取文件后，用JSON.parse()解析返回结果
    * 其余扩展名文件：它们都被当做.js文件载入

10. npm install -g是将一个包安装为全局可用的可执行命令
11. 前端模块化
    * CommonJS：CommonJS用同步的方式加载模块，在服务端，模块文件都存在本地磁盘，读取非常快，所以这样做不会有问题。但是在浏览器端，限于网络原因，更合理的方案是使用异步加载
    * AMD：异步模块定义，采用异步的方式加载模块，模块的加载不影响后面语句的执行，依赖前置，提前执行，定义模块时要对其依赖进行声明
    * CMD：通用模块定义，依赖就近，在需要时进行引入，延迟执行（并不是延迟加载），相对于AMD，更贴近CommonJS规范和Node Modules规范
    * ES6 Module，与CommonJS模块的差异：
        * CommonJS 模块输出的是一个值的拷贝，ES6 模块输出的是值的引用
            * CommonJS 模块输出的是值的拷贝，也就是说，一旦输出一个值，模块内部的变化就影响不到这个值
            * ES6 模块的运行机制与 CommonJS 不一样。JS 引擎对脚本静态分析的时候，遇到模块加载命令import，就会生成一个只读引用。等到脚本真正执行时，再根据这个只读引用，到被加载的那个模块里面去取值。换句话说，ES6 的import有点像 Unix 系统的“符号连接”，原始值变了，import加载的值也会跟着变。因此，ES6 模块是动态引用，并且不会缓存值，模块里面的变量绑定其所在的模块
        * CommonJS 模块是运行时加载，ES6 模块是编译时输出接口
            * 运行时加载: CommonJS 模块就是对象；即在输入时是先加载整个模块，生成一个对象，然后再从这个对象上面读取方法，这种加载称为“运行时加载”
            * 编译时加载: ES6 模块不是对象，而是通过 export 命令显式指定输出的代码，import时采用静态命令的形式。即在import时可以指定加载某个输出值，而不是加载整个模块，这种加载称为“编译时加载”
    CommonJS 加载的是一个对象（即module.exports属性），该对象只有在脚本运行完才会生成。而 ES6 模块不是对象，它的对外接口只是一种静态定义，在代码静态解析阶段就会生成

## 第三章 异步I/O

1. 为什么要异步I/O，这与Node面向网络而设计不无关系，具体到实处，从以下两个方面说起：
    * 用户体验：在浏览器中，JS在单线程上执行，且与UI渲染共用一个线程，这意味着当JS执行的时候，UI的渲染和响应是处于停滞状态的。如果网页需要临时获取一个资源，通过同步的方式获取，这期间UI将停顿，不响应用户的交互行为，可以想象，这样的用户体验将会多差。而采用异步请求，在资源的下载期间，JS和UI的执行都不会处于等待状态，可以继续响应用户的交互行为。前端可以通过异步消除掉UI阻塞的现象，但是前端获取资源的速度也取决于后端的响应速度，例如：两个资源获取耗时为M、N，如果采用同步方式耗时为M+N，异步方式则为Max(M, N)，因此只有后端能够快速响应资源，才能让前端的体验编号。
    * 资源分配：多线程的代价在于创建线程和执行期线程上下文切换的开销较大，另外，在复杂的业务中，多线程编程经常面临着锁和状态同步的问题。单线程的缺点在于性能，同步的编程模型导致的问题是，任意一个略慢的任务都会导致后续执行代码被阻塞，着造成资源不能被更好的利用。操作系统会将CPU的时间片分配给其余进程，以公平而有效地利用资源，基于这一点，有的服务器为了提升影响能力，会通过启动多个工作进程来为更多的用户服务。但是对于这一组人物而言，它无法分发任务到多个进程上，所以依然无法高效利用资源，结束所有任务所需的时间会比较长。
    因此，Node在两者之间给出了它的方案：利用单线程，远离多线程死锁、状态同步等问题；利用异步I/O，让单线程远离阻塞，以更好地使用CPU。为了弥补单线程无法利用多核CPU的缺点，Node提供了类似前端浏览器中的Web Workers的子进程，该子进程可以通过工作进程高效地利用CPU和I/O。
2. 从计算机内核I/O而言，异步/同步和阻塞/非阻塞实际上是两回事
3. 操作系统内核对于I/O只有两种方式：
    * 阻塞I/O：调用之后一定要等到系统内核层面完成所有操作后，调用才结束，造成CPU等待I/O，浪费等待事件，CPU的处理能力不能得到充分利用
    * 非阻塞I/O：调用之后立即返回
    非阻塞I/O返回之后，CPU的时间片可以用力处理其他事物，此时的性能提升是明显的。但非阻塞I/O也存在一些问题。由于完整的I/O并没有完成，立即返回的并不是业务层渴望的数据，而仅仅是当前调用的状态。为了获取完整的数据，应用程序需要重复调用I/O操作来确认是否完成。这种重复调用判断操作是否完成的技术叫做**轮询**

    阻塞I/O造成CPU等待浪费，非阻塞带来的麻烦却是需要轮询去确认是否完成完成数据获取，它会让CPU处理状态判断，是对CPU资源的浪费
4. 轮询技术：
    * read
    * select
    * poll
    * epoll：该方案是Linux下效率最高的I/O事件通知机制，在进入轮询的时候如果没有检查到I/O事件，将会进行休眠，直到事件发生将它唤醒。它是真实利用了事件通知、执行回调的方式，而不是遍历查询，所以不会浪费CPU，执行效率较高
    * kqueue：该方案的实现方式与epoll类似，不过它仅在FreeBSD系统下存在
5. 非阻塞I/O对于应用程序而言，它仍然只能算是一种同步，因为应用程序仍然需要等待I/O完全返回，依旧花费了很多时间来等待。等待期间，CPU幺妹用于遍历文件描述符的状态，要么用于休眠等待事件发生，对于当前线程而言利用率不够，理想的异步I/O是应用程序发起非阻塞调用，无需通过遍历或者事件唤醒等方式轮询，可以直接处理下一个任务。采用多线程的方式，通过让部分线程进行阻塞I/O或者非阻塞I/O加轮询技术来完成数据获取，让一个线程进行计算处理，通过线程之间的通信将I/O得到的数据进行传递，这就轻松实现了异步I/O。
6. Node是单线程的，这里的单线程仅仅只是JS执行在单线程中罢了。在Node中，无论是*nix还是Windows平台，内部完成I/O任务的另有线程池
7. **Node的异步I/O**
    * 事件循环：在进程启动时，Node便会创建一个类似于while(true)的循环，每执行一次循环体的过程我们称为Tick。每个Tick的过程就是查看是否有事件待处理，如果有，就取出事件及相关的回调函数。如果存在关联的回调函数，就执行它们。然后进入下个循环，如果不再有事件处理，就退出进程。
    * 观察者：每个事件循环中有一个或者多个观察者，而判断是否有事件要处理的过程就是向这些观察者询问是否有要处理的事件，一个观察者里可能有多个事件，在Node中，事件主要来源于网络请求、文件I/O等，这些事件对应的观察者有文件I/O观察者、网络I/O观察者等。观察者将事件进行了分类。事件循环是一个典型的生产者/消费者模型。异步I/O、网络请求等则是事情的生产者，源源不断为Node提供不同类型的事件，这些事件被传递到对应的观察者哪里，事件循环则从观察者那里取出事件并处理。在Windows下，这个循环基于IOCP创建，而在*nix下则基于多线程创建。
    * 请求对象：从JS发起调用到内核执行完I/O操作的过渡过程中，存在一种中间产物，它叫做请求对象，所有的状态都保存在这个对象中，包括送入线程池等待执行以及I/O操作完毕后的回调处理
    * 执行回调：线程池中的I/O操作调用完毕之后，会将结果存储在请求对象（req->result）属性上，然后通知IOCP，告知当前对象操作以完成。在每次Tick的执行中，它会调用IOCP相关的方法检查线程池中是否有执行完成的请求，如果存在，会将请求对象加入到I/O观察者的队列中，然后将其当做事件处理。I/O观察者回调函数的行为就是取出请求对象的result属性作为参数，取出oncomplete_sym属性作为方法，然后调用执行，以此达到调用JS中传入的回调函数的目的。
    **事件循环、观察者、请求对象、I/O线程池这四者共同构成了Node异步I/O模型的基本要素。**
8. **非I/O的异步API**
    * 定时器：调用setTimeout()或者setInterval()创建的定时器会被插入到定时器观察者内部的一个红黑树中。每次Tick执行时，会从该红黑树中迭代取出定时器对象，检查是否超过定时时间，如果超过，就形成一个事件，它的回调函数将立即执行。定时器的问题在于，它并非精确的（在容忍范围内）。尽管事件循环十分快，但是如果某一次循环占用的时间较多，那么下次循环时，它也许已经超时很久了。譬如通过setTimeout()设定一个任务在10毫秒后执行，但是在9毫秒后，有一个任务占用了5毫秒的CPU时间片，再次轮到定时器执行时，时间就已经过期4毫秒。
    * process.nextTick()：相当于setTimeout(fn, 0)，而由于时间循环自身的特点，定时器的精确度不够。而事实上，采用定时器需要动用红黑树，创建定时器对象和迭代等操作，而setTimeout(fn, 0)的方式较为浪费性能。实际上，process.nextTick()方法的操作相对较为轻量。每次调用process.nextTick()方法，只会将回调函数放入队列中，在下一轮Tick时取出执行。定时器采用红黑树的操作时间复杂度为O(lg(n))，nextTick()的时间复杂度为O(1)。
    * setImmediate()：setImmediate()方法与procee.nextTick()方法十分类似，都是将回调函数延迟执行。process.nextTick()中的回调函数执行的优先级要高于setImmediate()。这里的原因在于事件循环对观察者的检查是有先后顺序的，process.nextTick()属于idle观察者，setImmediate()属于check观察者。在每一个轮循环检查中，idle观察者先于I/O观察者，I/O观察者先于check观察者。在具体实现上，process.nextTick()的回调函数保存在一个数组中，setImmediate()的结果则是保存在链表中。在行为上，process.nextTick()在每轮循环中会将数组中的回调函数全部执行完，而setImmediate()在每轮循环中执行链表中的一个回调函数。之所以这样设计，是为了保证每次每轮循环能够较快地执行结束，防止CPU占用过多而阻塞后续I/O调用的情况。
9. 服务器模型：
    * 同步式：对于同步式的服务，一次只能处理一个请求，并且其余请求都处于等待状态
    * 每进程/每请求：为每个请求启动一个进程，这样可以处理多个请求，但是它不具备扩展性，因为系统资源只有那么多
    * 每线程/每请求：为每个请求启动一个线程来处理。尽管线程比进程要轻量，但是由于每个线程都占用一定内存，当大并发请求到来时，内存将会很快用光，导致服务器缓慢。
    Node通过事件驱动的方式处理请求，无须为每一个请求创建额外的对应线程，可以省掉创建线程和销毁线程的开销。知名服务器Nginx，也摒弃了多线程的方式，采用了和Node相同的事件驱动，不同之处在于Nginx采用纯C写成，性能较高，但是它仅适合于做Web服务器，用于反向代理或负载均衡等服务，在处理具体业务方面较为欠缺。

## 第四章 异步编程

1. 函数式编程
    * 高阶函数：可以把函数作为参数，或是将函数作为返回值的函数
    * 偏函数：通过指定部分参数来产生一个新的定制函数的形式就是偏函数
2. 异步编程优势：Node带来的最大特效莫过于**基于事件驱动的非阻塞I/O模型**，非阻塞I/O可以使CPU与I/O并不相互依赖等待，让资源得到更好的利用。利用事件循环的方式，JS线程像一个分配任务和处理结果的大管家，I/O线程池里的各个I/O线程都是小二，这个模型的缺点则在于管家无法承担过多的细节性任务，如果承担太多，则会影响到任务的调度，管家忙个不停，小二却得不到活干，结局则是整体效率的降低。换言之，Node是为了解决编程模型中阻塞I/O性能问题的，采用了单线程模型，这导致Node更像一个处理I/O密集型的能手，而CPU密集型则取决于管家的能耐如何。由于事件循环模型需要应对海量请求，海量请求同时作用在单线程上，就需要防止任何一个计算耗费过多的CPU时间片。至于是计算密集型，还是I/O密集型，只要计算不影响异步I/O的调度，那就不构成问题。建议对CPU的耗用不要超过10ms，或者将大量的计算分解为诸多的小量计算，通过setImmediate()进行调度。只要合理利用Node的异步模型和V8的高性能，就可以充分发挥CPU和I/O资源的优势。
3. 异步编程的难点：
    * 异常处理：过去我们处理异常时，通常使用类Java的try/catch/final语句块进行异常捕获。但是这对于异步编程不一定适用。第3章提到过，异步I/O的实现主要包含两个阶段：提交请求和处理结果。这两个阶段中间有事件循环的调度，两者彼此不关联。异步方法则通常在第一个阶段提交请求后立即返回，因为异常并不一定发生在这个阶段，try/catch的功效在此处不会发挥任何作用。

        ```javascript
        var async = function (callback) {
            process.nextTick(callback)
        }

        // 只能捕获当次事件循环内的异常，对callback执行时抛出的异常无能为力
        try {
            async(callback)
        } catch (e) {
            // TODO
        }
        ```

        Node在处理异常上形成了一种约定，将异常作为回调函数的第一个实参传回，如果为空值，则表明异步调用没有异常抛出：

        ```javascript
        async(function (err, results) {
            // TODO
        })
        ```

        在我们自行编写的异步方法上，也需要去遵循这样一些原则：
        * 原则1：必须执行调用者传入的回调函数
        * 原则2：正确传递回异常供调用者判断
    * 函数嵌套过深：对于Node而言，事务中存在多个异步调用的场景比比皆是，函数嵌套过深导致代码难以阅读
    * 阻塞代码：Node中没有sleep()这样的线程沉睡功能，唯独能用于延时操作的只有setTimeout()和setInterval()这两个函数。但是这两个函数并不能阻塞后续代码的执行。所以，有多半开发者会写出下述这样的代码来实现sleep(1000)的效果：

        ```javascript
        var start = new Date()
        while (new Date() - start < 1000) {
            // TODO
        }
        // 需要阻塞的代码
        ```

        但是事实是糟糕的，这段代码会持续占用CPU进行判断，与真正的线程沉睡相去甚远，完全破坏了事件循环的调度。由于Node单线程的原因，CPU资源全都会用于为这段代码服务，导致其余任何请求都会得不到响应。

        遇见这样的需求时，在同一规划业务逻辑之后，调用setTimeout()的效果会更好。
    * 多线程编程：JS运行在单线程之上，没有充分利用多核CPU，浏览器采用Web Workers，Node借鉴了这个模式，child_process是其基础API，cluster模块是更深层次的应用。
    * 异步转同步
4. 异步编程解决方案：
    * 事件发布/订阅模式：Node自身提供events模块，它具有addListener/on()、once()、removeListener()、removeAllListeners()和emit()等基本的时间监听模式的方法实现。值得一提的是，Node对事件发布/订阅的机制做了一些额外的处理，这大多是基于健壮性而考虑的。下面为两个具体的细节点：
        * 如果对一个事件添加了超过10个侦听器，将会得到一个警告。这一处设计与Node自身单线程运行有关，设计者认为侦听器太多可能导致内存泄漏。调用emitter.setMaxListeners(0)，可以将这个限制去掉。另一方面，由于事件发布会引起一系列侦听器执行，如果事件相关的侦听器过多，可能存在过多占用CPU的情景。
        * 为了异常处理，EventEmitter对象对error事件进行了特殊对待。如果允许期间的错误触发了error事件，EventEmitter会检查是否有队error事件添加过侦听器。如果添加了，这个错误将会交由改侦听器处理，否则这个错误将会作为异常抛出。如果外部没有捕获这个异常，将会引起线程退出。一个健壮的EventEmitter实例应该多error事件做处理。
        1. 继承events模块

            ```javascript
            var events = require('events')

            function Stream() {
                events.EventEmitter.call(this)
            }
            util.inherits(Stream, events.EventEmitter)
            ```

        2. 利用事件队列解决雪崩问题：所谓雪崩问题，就是在高访问量、大并发量的情况下缓存失效的情景，此时大量的请求同时涌入数据库中，数据库无法同时承受如此大的查询请求，进而往前影响到网站整体的响应速度。
            以下是一条数据库查询语句的调用：

            ```javascript
            var select = function (callback) {
                db.select('SQL', function (results) {
                    callback(results)
                })
            }
            ```

            如果站点刚好启动，这时缓存中是不存在数据的，而如果访问量巨大，同一句SQL会被发送到数据库中反复查询，会影响服务的整体性能。一种改进方案是添加一个状态锁，相关代码如下：

            ```javascript
            var status = 'ready'
            var select = function (callback) {
                if (status !== 'ready') {
                    return
                }

                status = 'pending'
                db.select('SQL', function (results) {
                    status = 'ready'
                    callback(results)
                })
            }
            ```

            但是在这种情况下，连续地多次调用select()时，只有第一次调用是生效的，后续的select()是没有数据服务的，这个时候可以引入事件队列，相关代码如下：

            ```javascript
            var proxy = new events.EventEmitter()
            var status = 'ready'
            var select = function (callback) {
                proxy.once('selected', callback)

                if (status !== 'ready') {
                    return
                }

                status = 'pending'
                db.select('SQL', function (results) {
                    proxy.emit('selected', results)
                    status = 'ready'
                })
            }
            ```

            此处可能因为存在侦听器过多引发警告，需要调用setMaxListeners(0)移除警告，或者设置更大的警告阈值
        3. 多异步之间的协作方案
            这里我们尝试通过原生代码解决“难点2”中为了最终结果的处理而导致可以并行调用但实际只能串行执行的问题。这里以渲染页面所需要的模板读取、数据读取和本地化资源读取为例简要介绍一下，相关代码如下：

            ```javascript
            var count = 0
            var results = {}
            var done = function (key, value) {
                results[key] = value
                count++

                if (count === 3) {
                    render(results)
                }
            }

            fs.readFile(template_path, 'utf8', function (err, template) {
                done('template', template)
            })
            db.query(sql, function (err, data) {
                done('data', data)
            })
            l10n.get(function (err, resources) {
                done('resources', resources)
            })
            ```

            由于多个异步场景中回调函数的执行并不能保证顺序，且回调函数之间互相没有任何交集，所以需要借助一个第三方函数和第三方变量来处理异步协作的结果。通常，我们把这个用于检测次数的变量叫做**哨兵变量**。这里可以利用偏函数来处理哨兵变量和第三方函数的关系，相关代码如下：

            ```javascript
            var after = function (times, callback) {
                var count = 0
                var results = {}

                return function (key, value) {
                    results[key] = value
                    count++

                    if (count === times) {
                        callback(results)
                    }
                }
            }
            var done = after(3, render)
            ```

            上述方案实现了多个事件对应一个侦听器的目的。如果业务继续增长，我们依然可以继续利用发布/订阅方式来完成多对多的方案，相关代码如下：

            ```javascript
            var emitter = new events.Emitter()
            var done = after(times, render)

            emitter.on('done', done)
            emitter.on('done', other)

            fs.readFile(template_path, 'utf8', function (err, template) {
                emitter.emit('done', 'template', template)
            })
            db.query(sql, function (err, data) {
                emitter.emit('done', 'data', data)
            })
            l10n.get(function (err, resources) {
                emitter.emit('done', 'resources', resources)
            })
            ```

            在上面的方法中，有一个令调用者不那么舒服的问题，那就是调用者要去准备这个done()函数，以及在回调函数中需要从结果把数据一个个提取出来，再进行处理。

            另一个方案则是来自于笔者自己写的EventProxy模块，相关代码如下：

            ```javascript
            var proxy = new EventProxy()

            proxy.all('template', 'data', 'resources', function (template, data, resource) {
                //TODO
            })

            fs.readFile(template_path, 'utf8', function (err, template) {
                proxy.emit('template', template)
            })
            db.query(sql, function (err, data) {
                proxy.emit('data', data)
            })
            l10n.get(function (err, resources) {
                proxy.emit('resources', resources)
            })
            ```

    * Promise/Deferred模式：使用事件的方式，执行流程需要被预先设定。Promise/Deferred模式可以先执行异步调用，延迟传递处理方

        ```javascript
        // 普通Ajax调用
        $.get('/api', {
            success: onSuccess,
            error: onError,
            complete: onComplete
        })

        // Promise/Deferred模式
        $.get('/api')
            .success(onSuccess)
            .success(onSuccess1)
            .error(onError)
            .complete(onComplete)
        ```

        这使得即使不调用success()、error()等方法，Ajax也会执行，并且可以处理多个回调
        Promise/Deferred模式发布在CommonJS规范中，CommonJS草案目前已经抽象出了Promises/A、Promises/B、Promises/D这样典型的异步Promise/Deferred模型
        1. Promises/A：
            Promise/A提议对单个异步操作做出了这样的抽象定义：
            * Promise操作只会处在3种状态的一种：未完成态、完成态和失败态
            * Promise的状态只会出现从未完成态向完成态或失败态转化，不能逆反。完成态和失败态不能互相转化
            * Promise的状态一旦转化，将不能被更改
            在API的定义上，一个Promise对象只要具备then()方法即可。对于then()方法，有以下要求：
            * 接受完成态、错误态的回调方法
            * 可选地支持progress事件回调作为第三个方法
            * then()方法只接受function对象，其余对象将被忽略
            * then()方法继续返回Promise对象，以实现链式调用
            then()方法定义如下：

                ```javascript
                then(fulfilledHandler, errorHandler, progressHandler)
                ```

            为了演示Promises/A提议，这里我们尝试通过继承Node的events模块来完成一个简单的实现，相关代码如下：

                ```javascript
                var Promise = function () {
                    EventEmitter.call(this)
                }
                util.inherits(Promise, EventEmitter)

                Promise.prototype.then = function (fulfilledHandler, errorHandler, progressHandler) {
                    if (typeof fulfilledHandler === 'function') {
                        // 利用once方法，保证成功回调只执行一次
                        this.once('success', fulfilledHandler)
                    }

                    if (typeof errorHandler === 'function') {
                        this.once('error', errorHandler)
                    }

                    if (typeof progressHandler === 'function') {
                        this.on('progress', progressHandler)
                    }

                    return this
                }
                ```
            这里看到then()方法所做的事情就是将回调函数存放起来。为了完成整个流程，还需要触发执行这些回调函数的地方，实现这些功能的对象通常被称为Deferred，即延迟对象，实例代码如下：

                ```javascript
                var Deferred = function () {
                    this.state = 'unfulfilled'
                    this.promise = new Promise()
                }

                Deferred.prototype.resolve = function (obj) {
                    this.state = 'fulfilled'
                    this.promise.emit('success', obj)
                }

                Deferred.prototype.reject = function (err) {
                    this.state = 'failed'
                    this.promise.emit('error', err)
                }

                Deferred.prototype.progress = function (data) {
                    this.promise.emit('progress', data)
                }
                ```
        2. Promise中的多异步协作

            ```javascript
            Deferred.prototype.all = function (promises) {
                let count = promises.length
                let results = []
                const that = this

                promises.forEach(function (promise, i) {
                    promise.then(function (data) {
                        count--
                        results[i] = data

                        if (count === 0) {
                            that.resolve(results)
                        }
                    }, function (err) {
                        that.reject(err)
                    })

                })
                return this.promise
            }
            ```

        3. Promise的进阶知识

            ```javascript
            // 让promise支持链式调用
            var Deferred = function () {
                this.promise = new Promise()
            }

            // 完成态
            Deferred.prototype.resolve = function (obj) {
                var promise = this.promise
                var handler
                while ((handler = promise.queue.shift())) {
                    if (handler && handler.fulfilled(obj)) {
                        var ret = handler.fulfilled(obj)
                        if (ret && ret.isPromise) {
                            ret.queue = promise.queue
                            this.promise = ret
                            return
                        }
                    }
                }
            }

            // 失败态
            Deferred.prototype.reject = function (obj) {
                var promise = this.promise
                var handler
                while ((handler = promise.queue.shift())) {
                    if (handler && handler.error(obj)) {
                        var ret = handler.error(obj)
                        if (ret && ret.isPromise) {
                            ret.queue = promise.queue
                            this.promise = ret
                            return
                        }
                    }
                }
            }

            // 生成回调函数
            Deferred.prototype.callback = function () {
                var that = this
                return function (err, file) {
                    if (err) {
                        return that.reject(err)
                    }
                    that.resolve(file)
                }
            }

            var Promise = function () {
                // 队列用于存储待执行的回调函数
                this.queue = []
                this.isPromise = true
            }

            Promise.prototype.then = function (fulfilledHandler, errorHandler, progressHandler) {
                var handler = {}

                if (typeof fulfilledHandler === 'function') {
                    handler.fulfilled = fulfilledHandler
                }

                if (typeof errorHandler === 'function') {
                    handler.error = errorHandler
                }

                this.queue.push(handler)
                return this
            }

            // 验证
            var readFile1 = function (file, encoding) {
                var deferred = new Deferred()
                fs.readFile(file, encoding, deferred.callback())
                return deferred.promise
            }
            var readFile2 = function (file, encoding) {
                var deferred = new Deferred()
                fs.readFile(file, encoding, deferred.callback())
                return deferred.promise
            }

            readFile1('file1.txt', 'utf8')
                .then(function (file1) {
                    return readFile2(file1.trim(), 'utf8')
                })
                .then(function (file2) {
                    console.log(file2)
                })
            ```

            要让Promise支持链式执行，主要通过以下两个步骤：
            1. 将所有回调都存到队列中
            2. Promise完成时，逐个执行回调，一旦检测到返回了新的Promise对象，停止执行，然后将当前Deferred对象promise引用改变为新的Promise对象，并将队列中余下的回调转交给它

            将API Promise化

            ```javascript
            var smooth = function (method) {
                return function () {
                    var deferred = new Deferred()
                    var args = Array.prototype.slice.call(arguments, 1)
                    args.push(deferred.callback())
                    method.apply(null, args)
                    return deferred.promise
                }
            }
            ```

    * 流程控制库：
        1. 尾触发与Next

            ```javascript
            function offWork(data, next) {
                console.log('上班ing。。。')
                setTimeout(function() {
                    console.log('下班了。。。')
                    next('传给下个任务的数据')
                }, 1000)
            }

            function backHome(data, next) {
                console.log('上个任务传过来的数据为：' + data)
                setTimeout(function() {
                    console.log('到家了！！！')
                    next('传给下个任务的数据')
                }, 1000)
                console.log('回家ing。。。')
            }

            App = {
                handles: [],
                use: function(handle) {
                    if (typeof handle == 'function') App.handles.push(handle)
                },
                next: function(data) {
                    var handlelist = App.handles
                    var handle = null
                    var _next = App.next
                    if ((handle = handlelist.shift()) != undefined) {
                        handle.call(App, data, _next)
                    }
                },
                start: function(data) {
                    App.next(data)
                }
            }

            App.use(offWork)
            App.use(backHome)
            App.start()
            ```

        2. async：流程控制模块
            * 无依赖异步的串行执行：async.series(asyncFnArray, callback)
            * 依赖异步的串行执行：async.waterfall(asyncFnArray, callback)
            * 异步的并行执行：async.parallel(asyncFNArray, callback)
            * 自动依赖处理：async.auto(depsArray)
        3. Step：流程控制模块
            * 依赖异步的串行执行：this
            * 并行执行任务：this.parallel()
            * 结果分组：this.group()
        4. wind：$await使得代码看起来像同步的代码
    * async/await

    流程控制小结：事件发布/订阅模式相对算是一种较为原始的方式，Promise/Deferred模式贡献了一个非常不错的异步任务模型的抽象。而上述的这些异步流程控制方案与Promise/Deferred模式的思路不同，Promise/Deferred的重头在于封装异步的调用部分，流程控制库则显得没有模式，将处理重点放置在回调函数的注入上。从自由度上来讲，async、Step这类流控库相对灵活得多。
5. 异步并发控制：异步并发量过大，会导致服务器崩溃。
    * bagpipe的解决方案：
        * 通过一个队列来控制并发量
        * 如果当前活跃（指调用发起但未执行回调）的异步调用量小于限定值，从队列中取出执行
        * 如果活跃调用达到限定值，调用暂时存放在队列中
        * 每个异步调用结束时，从队列中取出新的异步调用执行
    * async的解决方案：parallelLimit()

## 第五章 内存控制

1. V8对内存的使用进行了限制
2. V8的对象分配：在V8中，所有的JS对象都是通过堆来进行分配的，Node提供了process.memoryUsage()方法查看内存使用量，V8同样限制了堆的使用大小，表层原因是因为V8最初为浏览器设计，不太可能遇到用大量内存的场景。对于网页来说，V8的限制值已经绰绰有余。深层原因是V8的垃圾回收机制的限制。按官方的说话，以1.5GB的垃圾回收堆内存为例，V8做一次小的垃圾回收需要50毫秒以上，做一次非增量式的垃圾回收甚至要1秒以上。这是垃圾回收中引起JS线程暂停执行的时间，在这样的时间花销下，应用的性能和响应能力都会直线下降。当然，这个限制也不是不能打开，Node在启动时可以传递--max-old-space-size或--max-new-space-size来调整内存限制的大小
3. V8的垃圾回收机制：V8的垃圾回收策略主要基于分代式垃圾回收机制，按对象的存活时间将内存的垃圾回收进行不同的分代，然后分别对不同分代的内存施以更高效的算法
    * V8的内存分代：在V8中，主要将内存分为新生代和老生代。新生代中的对象为存活时间较短的对象，老生代中的对象为存活时间较长或常驻内存的对象，上述的--max-old-space-size和--max-new-space-size分别对应设置老生代和新生代内存的大小，老生代内存在64位系统和32位系统下分别只能使用约1.4GB和约0.7GB的大小，对于新生代内存，它由两个reserved_semispace_size_所构成，按机器位数的不同，reserved_semispace_size_在64位系统和32位系统下分别为16MB和8MB的大小，所以新生代内存的最大值在64位系统和32位系统上分别为32MB和16MB，V8堆内存的最大保留空间为：4 * reserved_semispace_size_ + ax-old-space-size_，因此，默认情况下，V8堆内存的最大值在64位系统上为1464MB，32位系统上则为732MB。
    * Scavenge算法：在分代的基础上，新生代对中的对象主要通过Scavenge算法进行垃圾回收。在Scavenge的具体实现中，主要采用了Cheney算法：将新生代内存堆等分为两个semispace，一个为From，另一个为To，当垃圾回收开始时，会从From空间中拷贝存活的对象到To空间，而非存活对象的空间将会被释放，完成复制后，From空间和To空间的角色发生对换。在一定条件下，需要将存货周期长的对象移动到老生代中，也就是完成对象晋升。对象晋升的条件主要有两个，一个是对象是否经历过Scavenge回收，一个是To空间的内存占用比超过限制（25%）。
    * Mark-Sweep：标记清除，Mark-Sweep在标记阶段遍历堆内存中的所有对象，并标记活着的对象，在随后的清除阶段，只清除没有被标记的对象。Mark-Sweep最大的问题就是，在进行一次清除回收以后，内存空间会出现不连续的状态。这种内存碎片会对后续的内存分配造成问题。如果出现需要分配一个大内存的情况，由于剩余的碎片空间不足以完成此次分配，就会提前触发垃圾回收，而这次回收是不必要的。
    * Mark-Compact：标记整理，为了解决Mark-Sweep的内存碎片问题。Mark-Compact在标记完存活对象以后，会将活着的对象向内存空间的一端移动，移动完成后，直接清理掉边界外的所有内存。
    * Mark-Sweep & Mark-Compact两者结合：由于Mark-Conpact需要移动对象，所以它的执行速度不可能很快，在取舍上，V8主要使用Mark-Sweep，在空间不足以对从新生代中晋升过来的对象进行分配时，才使用Mark-Compact
    * Incremental Marking：为了避免出现JS应用逻辑与垃圾回收器看到的不一致的情况，垃圾回收的3种基本算法都需要将应用逻辑暂停下来，待执行完垃圾回收后再恢复执行应用程序，对于新生代来说，默认配置得较小，且其中存活对象通常较少，全停顿（stop-the-world）的影响不大。但老生代通常配置的较大，且存活对象较多，全堆垃圾回收的标记、清理、整理等动作造成的停顿会比较可怕，因此，V8引入了增量标记、并行标记与并行清理，进一步利用多核性能降低每次停顿的时间。

    V8的垃圾回收机制分为新生代和老生代。

    新生代主要使用Scavenge进行管理，主要实现是Cheney算法，将内存平均分为两块，使用空间叫From，闲置空间叫To，新对象都先分配到From空间中，在空间快要占满时将存活对象复制到To空间中，然后清空From的内存空间，此时，调换From空间和To空间，继续进行内存分配，当满足那两个条件时对象会从新生代晋升到老生代。

    老生代主要采用Mark-Sweep和Mark-Compact算法，一个是标记清除，一个是标记整理。两者不同的地方是，Mark-Sweep在垃圾回收后会产生碎片内存，而Mark-Compact在清除前会进行一步整理，将存活对象向一侧移动，随后清空边界的另一侧内存，这样空闲的内存都是连续的，但是带来的问题就是速度会慢一些。在V8中，老生代是Mark-Sweep和Mark-Compact两者共同进行管理的。
4. 高效使用内存
    * 如果变量是全局变量（不通过var声明或定义在global变量上），其引用对象常驻在内存中（老生代中），可通过delete操作来删除引用关系或者将变量重新赋值，在接下来的老生代内存清除和整理过程中，会被回收释放。在V8中通过delete删除对象的属性有可能干扰V8的优化，所以通过赋值方式解除引用更好
    * 闭包
5. Node中的内存使用并非都是通过V8进行分配的。我们将那些不是通过V8分配的内存称为堆外内存。利用堆外内存可以突破内存限制，例如，Buffer对象，它不经过V8的内存分配机制，所以也不会有堆内存的大小限制。
6. 内存泄漏
    * 通常，造成内存泄漏的原因有如下几个：
        * 缓存
        * 队列消费不及时
        * 作用域未释放
    * 缓存限制策略：采用LRU算法的缓存失效策略
    * 直接将内存作为缓存使用，除了限制缓存的大小外，另外要考虑的事情是，进程之前无法共享内存。如果在进程内使用缓存，这些缓存不可避免地有重复，对物理内存的使用是一种浪费。如何使用大量缓存，目前比较好的解决方案是采用进程外的缓存，进程自身部存储状态。外部的缓存软件有着良好的缓存过期淘汰策略以及自有的内存管理，不影响Node进程的性能。它的好处很多，在Node中主要可以解决以下两个问题：
        * 将缓存转移到外部，减少常驻内存的对象的数量，让垃圾回收更高效
        * 进程之间可以共享缓存
7. 大内存应用：
    * stream模块
    * Buffer操作

## 第六章 理解Buffer

1. Buffer对象类似于数组，用于操作字节，它的元素为16进制的两位数，即0到255的数值
2. Buffer内存分配
    * 采用slab分配机制，slab是一种动态内存管理机制，简单而言，slab就是一块申请好的固定大小的内存区域。slab具有如下3种状态：
        * full：完全分配状态
        * partial：部分分配状态
        * empty：没有被分配状态
    * Node以8KB为界限来区分Buffer是大对象还是小对象，Buffer.poolSize = 8 * 1024，这个8KB的值也就是每个slab的大小值，在JS层面，以它作为单位单元进行内存的分配
    * 真正的内存是在Node的C++层面提供的，JS层面只是使用它。当进行小而频繁的Buffer操作时，采用slab的机制进行预先申请和事后分配，使得JS到操作系统之间不必有过多的内存申请方面的系统调用。对于大块的Buffer而言，则直接使用C++层面提供的内存，而无需细腻的分配操作
3. Buffer的转换
    1. 字符串转Buffer：new Buffer(str, [encoding])、buf.write(string, [offest], [length], [encoding])
    2. Buffer转字符串：buf.toString([encoding], [start], [end])
4. Buffer不支持的编码类型：可通过iconv、icon-lite模块进行转换
5. Buffer的拼接：Buffer在使用场景中，通常是以一段一段的方式传输

    ```javascript
    var fs = require('fs')
    var rs = fs.createReadStream('test.md')
    var data = ''

    rs.on('data', function (chunk) {
        data += chunk // 隐藏了toString()操作，等价于data = data.toString() + chunk.toString()
    })
    rs.on('end', function () {
        console.log(data)
    })
    ```

    上述代码对于英文，toString()不会造成任何问题，但对于宽字节的中文，却会形成问题，中文字在UTF-8下占3个字节，当这3个字节分部在上述代码中的不同chunk时，会造成这3个字节以乱码的形式呈现，

    * setEncoding()与string_decoder()：可读流可通过readable.setEncoding(encoding)设置编码方式，让data事件中传递的不再是一个Buffer对象，而是编码后的字符串。事实上，在调用setEncoding()时，可读流对象在内部设置了一个decoder对象，StringDecoder在得到编码后，知道宽字节字符在UTF-8编码下是以3个字节的方式存储的，所以当输出时不满足3个字符的条件时，会将剩余字符和后续输出的字符合并，再次用3的整数倍字节进行转码。于是乱码问题通过这种中间形式被解决了，但是它目前只能处理UTF-8、Base64和UCS-2/UTF-16LE这3种编码
    * 正确拼接Buffer

    ```javascript
    var chunks = []
    var size = 0
    res.on('data', function (chunk) {
        chunks.push(chunk)
        size += chunk.length
    })
    res.on('end', function () {
        var buf = Buffer.concat(chunks, size)
        var str = iconv.decode(buf. 'utf8')
        console.log(str)
    })

    Buffer.concat = function (list, length) {
        if (!Array.isArray(list)) {
            throw new Error('Usage: Buffer.concat(list, [lenght])')
        }

        if (list.length === 0) {
            return new Buffer(0)
        }

        if (list.length === 1) {
            return list[0]
        }

        if (typeof length !== 'number') {
            length = 0
            for (var i = 0; i < list.length; i++) {
                var buf = list[i]
                length += buf.length
            }
        }

        var buffer = new Buffer(length)
        var pos = 0
        for (var i = 0; i < list.length; i++) {
            var buf = list[i]
            buf.copy(buffer, pos)
            pos += buf.length
        }

        return buffer
    }
    ```

6. Buffer与性能
    * 在应用中，我们通常会操作字符串，但一旦在网络中传输，都需要转化为Buffer，以进行二进制数据传输，字符串与Buffer的转换有性能损耗，在Node构建的Web应用中，可以选择将页面中的动态内容和静态内容分离，静态内容部分可以通过预先转换为Buffer的方式，使性能得到提升。由于文件自身是二进制数据，所以在不需要改变内容的场景下，尽量只读取Buffer，然后直接传输，不做额外的转换，避免损耗。
    * 在文件的读取时，有一个highWaterMark设置对性能的影响至关重要，主要有两个影响的点：
        * highWaterMark设置对Buffer内存的分配和使用有一定影响，当读取一个相同的大文件时，highWaterMark值越大，读取速度越快
        * highWaterMark设置过小，可能导致系统调用次数过多

## 第七章 网络编程

1. Node提供了net、dgram、http、https这4个模块，分别用于处理TCP、UDP、HTTP、HTTPS，适用于服务器端和客服端。
2. TCP的服务事件：服务器可以同时与多个客户端保持连接，对于每个连接而言是典型的可写可读Stream对象
    * 服务器事件
        * listening：在调用server.listen()绑定端口或者Domain Socket后触发，简介写法为server.listen(port, listeningListener)，通过listen()方法的第二个参数传入
        * connection：每个客户端套接字埒街道服务器端时触发，简洁写法为通过net.createServer()，最后一个参数传递
        * close：当服务器关闭时触发，在调用server.close()后，服务器将停止接受新的套接字连接，但保持当前存在的连接，等待所有连接都断开后，会触发该事件
        * error：当服务器发生异常时，将会触发该事件。比如侦听一个使用中的端口，将会触发一个异常，如果不侦听error事件，服务器将会抛出异常
    * 连接事件（socket）
        * data：当一端用write()发送数据时，另一端会触发data事件，事件传递的数据即使write()发送的数据
        * end：当连接中的任意一端发送了FIN数据时，将会触发该事件
        * connect：该事件用于客户端，当套接字与服务端连接成功时会被触发
        * drain：当任意一端调用write()发送数据时，当前这端会触发该事件
        * error：当异常发生时，触发该事件
        * timeout：当一定时间后连接不再活跃时，该事件将会被触发，通知用户当前连接已经被闲置了
    另外，由于TCP套接字是可写可读的Stream对象，可以利用pipe()方法巧妙地实现管道操作，如下代码实现了一个echo服务器：

    ```javascript
    var net = require('net')

    var server = net.createServer(function (socket) {
        socket.write('Echo server\r\n')
        socket.pipe(socket)
    })
    ```

    值得注意的是，TCP针对网络中小的数据包有一定的优化策略：Nagle算法。如果每次只发送一个字节的内容而不优化，网络中将充满只有极少数有效的数据包，将十分浪费网络资源。Nagle算法针对这种情况，要求缓存区的数据达到一定数量或者一定时间后才将其发出，所以小数据包将会被Nagle算法合并，以此来优化网络。这种优化虽然使网络带宽被有效地使用，但是数据有可能被延迟发送

    在Node中，由于TCP默认启用了Nagle算法，可以调用socket.setNoDealy(true)去掉Nagle算法，使得write()可以立即发送数据到网络中

    另一个需要注意的是，尽管在网络的一端调用write()会触发另一端的data事件，但是并不意味着每次write()都会触发一次data事件，在关闭掉Nagle算法后，另一端可能会将接收到的多个小数据包合并，然后只触发一次data事件
3. 构建UDP服务：UDP又称用户数据包协议，与TCP一样同属于网络传输层。UDP与TCP最大的不同是UDP不是面向连接的。TCP中连接一旦建立，所有的会话都基于连接完成，客户端如果要与另一个TCP服务通信，需要另创建一个套接字来完成连接。但在UDP中，一个套接字可以与多个UDP服务通信，它虽然提供面向事务的简单不可靠信息传输服务，在网络差的情况下存在丢包严重的问题，但是由于它无须连接，资源消耗低，处理快速且灵活，所以常常应用在那种偶尔丢一两个数据包也不会产生重大影响的场景，比如音频、视频等。UDP目前应用很广泛，DNS服务即使基于它实现的。
    * UDP套接字事件
        * message：当UDP套接字侦听到网卡端口后，接收到消息时触发该事件，触发携带的数据为消息Buffer对象和一个远程地址信息
        * listening：当UDP套接字开始侦听时触发该事件
        * close：调用close()方法时触发该事件，并不再触发message事件。如需再次触发message事件，重新绑定即可
        * error：当异常发生时触发该事件，如果不侦听，异常将直接抛出，使进程退出
4. 构建HTTP服务：在Node中，HTTP服务继承自TCP服务器（net模块），http模块将连接所用套接字的读写抽象为ServerRequest和ServerResponse对象，它们分别对应请求和响应操作。在请求产生的过程中，http模块拿到连接传来的数据，调用二级制模块http_parser进行解析，在解析完请求报文的报头后，触发request事件，调用用户的业务逻辑。
    * HTTP请求
        * req.method
        * req.url
        * req.httpVersion
    * HTTP响应
        * 设置报文头信息：res.setHeader，可以调用多次进行设置，但是只有调用writeHead后，报头才会写入到连接中，除此之外，http模块会自动帮你设置一些头信息
        * 设置报文体信息：res.write()和res.end()，后者与前者的差别在于res.end()会先调用write()发送数据，然后发送信号告知服务器这次响应结束。响应结束后，HTTP服务器可能会将当前的连接用于下一个请求，或者关闭连接。值得注意的是，报头是在报文体发送前发送的，一旦开始了数据的发送，writeHead()和setHeader()将不再生效。这由协议的特效决定。
        另外，无论服务器端在处理业务逻辑时是否发生异常，务必在结束时调用res.end()结束请求，否则客户端将一直处于等待的状态。
    * HTTP服务的事件
        * connection：在开始HTTP请求和响应前，客户端与服务器端需要建立底层的TCP连接，这个连接可能因为开启了keep-alive，可以在多次请求响应之间使用；当这个连接建立时，服务器触发一次connection事件。
        * request：建立TCP连接后，http模块底层将在数据流中抽象出HTTP请求和HTTP响应，当请求数据发送到服务器端，在解析出HTTP请求头后，将会触发该事件；在res.end()后，TCP连接可能将用于下一次请求响应。
        * close：与TCP服务器的行为一致，调用server.close()方法停止接受新的连接，当已有的连接都断开时，触发该事件；可以给server.close()传递一个回调函数来快速注册该事件。
        * checkContinue：某些客户端在发送较大的数据时，并不会将数据直接发送，而是先发送一个头部带Expect: 100-continue的请求到服务器，服务器将会触发checkContinue事件；如果没有为服务器监听这个事件，服务器会自动响应客户端100 Continue的状态码，表示接受数据上传；如果不接受数据的较多时，响应客户端400 Bad Request拒绝客户端继续发送数据即可。需要注意的是，当该事件发生时不会触发request事件，两个事件互斥。当客户端收到100 Continue后重新发起请求时，才会触发request事件。
        * connect：当客户端发起CONNECT请求时触发，而发起CONNECT请求通常在HTTP代理时出现；如果不监听该事件，发起该请求的连接将会关闭。
        * upgrade：当客户端要求升级连接的协议时，需要和服务器端协商，客户端会在请求头中带上Upgrade字段，服务器端会在接受到这样的请求时触发该事件。如果不监听该事件，发起请求的连接将会关闭。
        * clientError：连接的客户端触发error事件时，这个错误会传递到服务器端，此时触发该事件。
5. 构建HTTP客户端：http.request(options, connect)
    * options参数决定了这个HTTP请求头中的内容，它的选项有如下这些
        * host：服务器的域名或IP地址，默认为localhost
        * hostname：服务器名称
        * port：服务器端口，默认为80
        * localAddress：建立网络连接的本地网卡
        * socketPath：Domain套接字路径
        * method：HTTP请求方法，默认为GET
        * path：请求路径，默认为/
        * headers：请求头对象
        * auth：Basic认证，这个值将被计算成请求头中的Authorization部分
        报文体的内容由请求对象的write()和end()方法实现：通过write()方法向连接中写入数据，通过end()方法告知报文结束。它与浏览器中的Ajax调用几近相同，Ajax的实质就是一个异步的网络HTTP请求。
    * HTTP响应：HTTP客户端的响应对象与服务器端较为类似，在ClientRequest对象中，它的事件叫做response。ClientRequest在解析响应报文时，一解析完响应头就触发response事件，同时传递一个响应对象以供操作ClientResponse。后续响应报文体以只读流的方式提供。
    * HTTP代理：为了重用TCP连接，http模块包含了一个默认的客户端代理对象http.globalAgent。它对每个服务器端（host + port）创建的连接进行了管理，默认情况下，通过ClientRequest对象对同一个服务端发起的HTTP请求最多可以创建5个连接。它的实质是一个连接池。调用HTTP客户端同时对一个服务器发起10次HTTP请求时，其实质只有5个请求处于并发状态，后续的请求需要等待某个请求完成服务后猜真正发出。可在options中传递agent选项。默认情况下，请求会采用全局的代理对象，默认连接数限制的为5。

        ```javascript
            var agent = new http.Agent({
                maxSockets: 10
            })

            var options = {
                hostname: '127.0.0.1',
                port: 1334,
                path: '/',
                method: 'GET',
                agent: agent
            }
        ```

    也可以设置agent选项为false值，以多里连接池的管理，使得请求不受并发限制。

    Agent对象的sockets和requests属性分别表示当前连接池中使用中的连接数和处于等待状态的请求数，在业务中监视着两个值有助于发现业务状态的繁忙程度。
    * HTTP客户端事件
        * response：与服务器端的request事件对应的客户端在请求发出后得到服务器端响应时，会触发该事件。
        * socket：当底层连接池中建立的连接分配给当前请求对象时，触发该事情。
        * connect：当客户端向服务器端发送CONNECT请求时，如果服务器端响应了200状态码，客户端将会触发该事件。
        * upgrade：客户端向服务器端发起Upgrade请求时，如果服务器端响应了101 Switching Protocols状态，客户端将会触发该事件。
        * continue：客户端向服务器端发起Expect: 100-continue头信息，以试图发送较大数据量，如果服务器端响应100 Continue状态，客户端将触发该事件。
6. 构建WebSocket服务
    * WebSocket服务与Node之间的配合堪称完美，其理由有两条：
        * WebSocket客户端基于事件的编程模型与Node中自定义事件相差无几
        * WebSocket实现了客户端与服务端之间的长连接，而Node事件驱动的方式十分擅长与大量的客户端保持高并发连接。
    * WebSocket与传统HTTP有如下好处：
        * 客户端与服务器端只建立一个TCP连接，可以使用更少的连接
        * WebSocket服务器端可以推送数据到客户端，这远比HTTP请求响应模式更灵活、更高效
        * 有更轻量级的协议头，减少数据传送量
    * 在WebSocket之前，网页客户端与服务器端进行通信最高效的是Comet（彗星）技术。实现Comet技术的细节是采用长轮询（long-polling）或iframe流。长轮询的原理是客户端向服务器端发起请求，服务器端只在超时或有数据响应时断开连接（res.end()）；客户端在收到数据或超时后重新发起请求。
    * WebSocket协议主要分为两个部分：握手和数据传输
        * WebSocket握手

            客户端建立连接时，通过HTTP发起请求报文，如下所示：

            ```javascript
            GET /chat HTTP/1.1
            HOST: server.example.com
            Upgrade: websocket
            Connection: Upgrade
            Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==
            Sec-WebSocket-Version: 13
            ```

            与普通的HTTP请求协议略有区别的部分在于如下这些协议头：

            ```javascript
                Upgrade: websocket
                Connection: Upgrade
            ```

            上述两个字段表示请求服务器端升级协议为WebSocket。其中Sec-WebSocket-Key用于安全校验

            Sec-WebSocket-Key的值是随机生成的Base64编码的字符串。服务器端接收到之后将其与字符串258EAFA5-E914-47DA-95CA-C5AB0DC85B11相连，然后通过sha1安全散列算法计算出结果后，再进行Base64编码，最后返回给客户端。这个算法如下所示：

            ```javascript
            var crypto = require('crypto')
            var val = crypto.createHash('sha1').update(key).digest('base64')
            ```

            另外，下面两个字段指定子协议和版本号：

            ```javascript
            Sec-WebSocket-Protocol: chat, superchat
            Sec-WebSocket-Version: 13
            ```

            服务器端处理完请求后，响应如下报文：

            ```javascript
            HTTP/1.1 Switching Protocols
            Upgrade: websocket
            Connection: Upgrade
            Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=
            Sec-WebSocket-Protocol: chat
            ```

            上面的报文告之客户端正在更换协议，更新应用层协议为WebSocket协议，并在当前的套接字连接上应用新协议。剩余的字段分别表示服务器端基于Sec-WebSocket-Key生成的字符串和选中的子协议。客户端将会校验Sec-WebSocket-Accept的值，如果成功，将开始接下来的数据传输。

        * WebSocket数据传输

            在握手顺利完成后，当前连接将不再进行HTTP的交互，而是开始WebSocket的数据帧协议，实现客户端与服务器端的数据交换

            为了安全考虑，客户端需要对发送的数据帧进行掩码处理，服务器一旦受到无掩码帧（比如中间拦截破坏），连接将关闭。而服务器发送到客户端的数据帧无需做掩码处理，同样，如果客户端收到带掩码的数据帧，连接也将关闭。
7. 网络服务与安全
    * 在网景公司的NetScape浏览器推出之初就提出了SSL(Secure Sockets Layer，安全套阶层)。SSL作为一种安全协议，它在传输层提供对网络连接加密的功能。对于应用层而言，它是透明的，数据在传递到应用层之前就已经完成了加密和解密的过程。最初的SSL应用在Web上，被服务器端和浏览器端同时支持，随后IETF将其标准化，称为TLS(Transport Layer Security，安全传输层协议)
    * Node在网络安全上提供了3个模块，分别为crypto、tls、https。其中crypto主要用于加密解密，SHA！、MD5等加密算法都在其中有体现。真正用于网络的是另外两个模块，tls模块提供了与net模块类似的功能，区别在于它建立在TLS/SSL加密的TCP连接上。对于https而言，它完全与http模块接口一致，区别也仅在于它建立于安全的连接之上。
    * TLS/SSL
        * 密钥：TLS/SSL是一个公钥/私钥的结构，它是一个非对称的结构，每个服务器端和客户端都有自己的公私钥。公钥用来加密要传输的数据，私钥用来解密接收到的数据。公钥和私钥是配对的，通过公钥加密的数据，只有通过私钥才能解密，所以在建立安全传输之前，客户端和服务器端之间需要互换公钥。客户端发送数据时要通过服务器端的公钥进行加密，服务器端发送数据时则需要客户端的公钥进行加密。
        * Node在底层采用的是openssl实现TLS/SSL
        * 数字证书：为了确保数据安全，引入了一个第三方：CA(Certificate Authority，数字证书认证中心)。CA的作用是为站点颁发证书，且这个证书中具有CA通过自己的公钥和私钥实现的签名。

        为了得到签名证书，服务器端需要通过自己的私钥生成CSR(Certificate Signing Request，证书签名请求)文件。CA机构将通过这个文件颁发属于该服务器端的签名证书，只要通过CA机构就能验证证书是否合法。

        通过CA机构颁发证书通常是一个烦琐的过程，需要付出一定的精力和费用。对于中小型企业而言，多半是采用自签名证书来构建安全网络的。所谓自签名证书，就是自己扮演CA机构，给自己的服务器端颁发签名证书。

        客户端在发起安全连接前会去获取服务器端的证书，并通过CA的证书验证服务器端的证书的真伪。除了验证真伪外，通常还含有对服务器名称、IP地址等进行验证的过程。
8. TLS服务：与普通的TCP服务器端和客户端相比，TLS的服务器端和客户端仅仅只在证书的配置上有差别，其余部分基本相同，在Node中，通过tls模块搭建TLS服务。
9. HTTPS服务：HTTPS服务就是工作在TLS/SSL上的HTTP

## 第八章 构建Web应用

1. 基础功能
    * 请求方法

        ```javascript
        function (req, res) {
            switch (req.method) {
                case 'POST':
                    update(req, res)
                    break
                case 'DELETE':
                    remove(req, res)
                    break
                case 'PUT':
                    create(req, res)
                    break
                case 'GET':
                default:
                    get(req, res)
            }
        }
        ```

    * 路径解析：客户端代理（浏览器）会将这个地址解析成报文，将路径和查询部分放在报文第一行。需要注意的是，hash部分会被丢弃，不会存在于报文的任何地方。
        * 根据路径去查找磁盘中的文件，然后将其响应给客户端

            ```javascript
            function (req, res) {
                const pathname = url.parse(req.url).pathname
                fs.readFile(path.join(ROOT, pathname), function (err, file) {
                    if (err) {
                        res.writeHead(404)
                        res.end('找不到相关文件。- -')
                        return
                    }
                    res.writeHead(200)
                    res.end(file)
                })
            }
            ```

        * 根据路径来选择控制器

            ```javascript
                // request url: /controller/action/a/b/c
                function (req, res) {
                    const pathname = url.parse(req.url).pathname
                    const paths = pathname.split('/')
                    const controller = paths[1] || 'index'
                    const action = paths[2] || 'index'
                    const args = path.slice(3)

                    if (handles[controller] && handles[controller][action]) {
                        handles[controller][action].apply(null, [req, res].concat(args))
                    } else {
                        rew.writeHead(200)
                        res.end('找不到响应控制器')
                    }
                }
            ```

            这样我们的业务部分可以只关心具体的业务实现，如下所示：

            ```javascript
                handles.index = {}
                handles.index.index = function (req, res, foo, bar) {
                    res.writeHead(200)
                    res.end(foo)
                }
            ```

    * 查询字符串
        查询字符串位于路径之后，在地址栏中路径后的?foo=bar&baz=val字符串就是查询字符串。这个字符串会跟随在路径后，形成请求报文首行的第二部分。这部分内容经常需要为业务逻辑所用，Node提供了queryString模块用于处理这部分数据，如下所示：

        ```javascript
        const url = require('url')
        const querystring = require('querystring')
        const query = querystring.parse(url.parse(req.url).query)
        // const query = url.parse(req.url, true).query
        ```

        要注意的点是，如果查询字符串中的键出现多次，那么它的值会是一个数组
    * Cookie
        * Cookie的处理分为如下几步：
            * 服务器向客户端发送Cookie
            * 浏览器将Cookie保存
            * 之后每次浏览器都会将Cookie发向服务器端
        * 解析Cookie

            ```javascript
                function parseCookie (cookie) {
                    let cookies = {}

                    if (!cookie) {
                        return cookies
                    }

                    let list = cookie.split(';')
                    for (let i = 0; i < list.length; i++) {
                        let pair = list[i].split('=')
                        cookies[pair[0].trim()] = pair[1]
                    }
                    return cookies
                }
           ```

        * 服务器通过Set-Cookie字段往客户端写入Cookie

            ```javascript
                Set-Cookie: name=value; Path=/; Expires=Sun, 23-Apr-23 09:01:35 GMT; Domain=.domain.com;
            ```

            其中name=value是必须包含的部分，其余部分皆是可选参数。这些可选参数将会影响浏览器在后续将Cookie发送给服务器端的行为。以下为主要的几个选项：
            * path表示这个Cookie影响到的路径，当前访问的路径不满足该匹配时，浏览器则不发送这个Cookie。
            * Expires和Max-Age是用来告知浏览器这个Cookie何时过期的，如果不设置该选项，在关闭浏览器是会丢失掉这个Cookie。Expires的值是一个UTC格式的时间字符串，是绝对时间，如果客户端和服务器端的时间不匹配，这种时间设置就会存在偏差。为此，Max-Age告知浏览器这条Cookie多久之后过期，而不是一个具体的时间。
            * HttpOnly告知浏览器不允许通过脚本document.cookie去更改这个Cookie值，事实上，设置HTTPOnly之后，这个值在document.cookie中不可见。但是在HTTP请求的过程中，依然会发送这个Cookie到服务器端。
            * Secure：当Secure为true时，在HTTP中是无效的，在HTTPS中才有效，表示创建的Cookie只能在HTTPS连接中被浏览器传递到服务器端进行会话验证，如果是HTTP连接则不会传递该信息，所以很难被窃听到。
            Cookie序列化成符合规范的字符串

            ```javascript
                function serialize (name, val, opt) {
                    var pairs = [name + '=' + encode(val)]
                    opt = opt || {}

                    if (opt.maxAge) pairs.push('Max-Age=' + opt.maxAge)
                    if (opt.domain) pairs.push('Domain=' + opt.domain)
                    if (opt.path) pairs.push('Path=' + opt.path)
                    if (opt.expires) pairs.push('Expires=' + opt.expires.toUTCString())
                    if (opt.httpOnly) pairs.push('HttpOnly')
                    if (opt.secure) pairs.push('Secure')

                    return pairs.join('; ')
                }
            ```

        * Cookie的性能影响：由于Cookie的实现机制，一旦服务器端向客户端发送了设置Cookie的意图，除非Cookie过期，否则客户端每次请求都会发送这些Cookie到服务器端，一旦设置的Cookie过多，将会导致报头较大。大多数的Cookie并不需要每次都用上，因为这会造成带宽的部分浪费。在YSlow的性能优化有规则中有这么一条：
            * 减小Cookie的大小：更严重的情况是，如果在域名的根节点设置Cookie，几乎所有子路径下的请求都会带上这些Cookie，这些Cookie在某些情况下是有用的，但是在有些情况下是完全无用的。其中以静态文件最为典型，静态文件的业务定位几乎不关心状态，Cookie对它而言几乎是无用的，但是一旦有Cookie设置到相同域下，它的请求中就会带上Cookie。好在Cookie设计时限定了它的域，只有域名相同时才会发送。所以YSlow中有另外一条规则用来避免Cookie带来的性能影响。
            * 为静态组件使用不同的域名：简而言之就是，为不需要Cookie的组件换个域名可以实现减少无效Cookie的传输。所以很多网站的静态文件会有特别的域名，使得业务相关的Cookie不再影响静态资源。当然换用额外的域名带来的好处不只这点，还可以突破浏览器下载线程数量的限制，因为域名不同，可以将下载线程数翻倍。但是换用额外域名还是有一定的确定的，那就是将域名转换为IP需要进行DNS查询，多一个域名就多一次DNS查询。YSlow中有这样一条规则：
            * 减少DNS查询：看起来减少DNS查询和使用不同的域名是冲突的两条规则，但是好在现今的浏览器都会进行DNS缓存，以削弱这个副作用的影响
    * Session
        * 如何将每个客户和服务器中的数据一一对应起来？
            * 第一种：基于Cookie来实现用户和数据的映射
                虽然将所有数据都放在Cookie中不可取，但是将口令放在Cookie中还是可以的。因为口令一旦被篡改，就丢失了映射关系，也无法修改服务器端存在的数据了。并且Session的有效期通常较短，普遍的设置是20分钟，如果在20分钟内客户端和服务器端没有交互产生，服务器端就将数据删除。由于数据过期时间较短，且在服务器端存储数据，因此安全性相对较高。那么口令是如何参数的呢？

                一旦服务器端启用了Session，它将约定一个键值作为Session的口令，这个值可以随意约定，比如Connect默认采用connect_uid，Tomact会采用jsessionid等。一旦服务器检查到用户请求Cookie中没有携带该值，它就会为之生成一个值，这个值时唯一且不重复的值，并设定超时时间
            * 第二种：通过查询字符串来实现浏览器端和服务器端数据的对应
                它的原理是检查请求的查询字符串，如果没有值，会先生成新的带值得URL，然后形成跳转，让客户端重新发起请求，

                有的服务器在客户端禁用Cookie时，会采用这种方案实现退化。通过这种方案，无须再响应时设置Cookie。但是这种方案带来的风险源大于基于Cookie实现的风险，因为只要将地址栏中的地址发给另外一个人，那么他就拥有跟你相同的身份。Cookie的方案在换了浏览器或者换了电脑之后无法生效，相对较为安全。

                还有一种比较有趣的处理Session的方式是利用HTTP请求头中的ETag，同样对于更换浏览器和电脑后也是无效的。
        * Session与内存
            Session数据直接存于内存中会带来极大的隐患，如果用户增多，我们很可能就接触到了内存限制的上限，并且内存中的数据量加大，必然会引起垃圾回收的频繁扫描，引起性能问题。

            另一个问题则是我们可能为了利用多核CPU而启动了多个进程。用户请求的连接将可能随意分配到各个进程中，Node的进程与进程之间是不能直接共享内存的，用户的Session可能会引起错乱。

            为了解决性能问题和Session数据无法跨进程共享的问题，常用的方案是将Session集中化，将原本可能分散在多个进程里的数据，统一转移到集中的数据存储中。目前常用的工具是Redis、Memcached等，通过这些高效的缓存，Node进程无须在内部维护数据对象，垃圾回收问题和内存限制问题都可以迎刃而解。

            采用第三方缓存来存储Session引起的一个问题是会引起网络访问。理论上来说访问网络中的数据要比访问本地磁盘中的数据速度还要慢，因为涉及到握手、传输以及网络终端自身的磁盘I/O等，尽管如此但依然会采用这些高速缓存的理由有以下几条：
            * Node与缓存服务保持长连接，而非频繁的短连接，握手导致的延迟只影响初始化
            * 高速缓存直接在内存中进行数据存储和访问
            * 缓存服务通常与Node进程运行在相同的机器上或者相同的机房里，网络速度影响较小
        * Session与安全
            从前文可以知道，尽管我们的数据都放置在后端了，使得它能保障安全，但是无论通过Cookie，还是查询字符串的实现方式，Session的口令依然保存在客户端，这里会存在口令被盗用的情况。如果Web应用的用户十分多，自行设计的随机算法的一些口令值就有理论机会命中有效的口令值。一旦口令被伪造，服务器端的数据也可能间接被利用。

            有一种做法是将这个口令通过私钥加密进行签名，使得伪造的成本较高。客户端尽管可以伪造口令值，但是由于不知道私钥值，签名信息很难伪造。如此，我们只要在响应时将口令和签名进行对比，如果签名非法，我们将服务器端的数据立即过期即可。

            这样一来，即使攻击者知道口令中.号前的值时服务器端Session的ID值，只要不知道secret私钥的值，就无法伪造签名信息，以此实现对Session的保护。

            当然，将口令进行签名是一个很好的解决方案，但是如果攻击者通过某种方式获取了一个真实的口令和签名，他就能实现身份的伪装。一种方案是将客户端的某些独有信息和口令作为原值，然后签名，这样攻击者一旦不在原始的客户端上进行访问，就会导致签名失败。这些独有信息包括用户IP和用户代理（User Agent）。
    * 缓存
        YSlow中提到了几条关于缓存的规则
        * 添加Expires或Cache-Control到报文头中
        * 配置ETags
        * 让Ajax可缓存
        通常来说，POST、DELETE、PUT这类待行为性的请求操作一般不做任何缓存，大多数缓存只应用在GET请求中
    * Basic认证：Basic认证是当客户端与服务器端进行请求时，允许通过用户名和密码实现的一种身份认证方式。如果一个页面需要Basic认证，它会检查请求报文头中的Authorization字段的内容，该字段的值由认证方式和加密值构成。在Basic认证中，它会将用户和密码部分组合，然后进行Base64编码，如果用户首次访问该网页，URL地址中页没携带认证内容，那么浏览器会响应一个401未授权的状态码。响应头中的WWW-Authenticate字段告知浏览器采用什么样的认证和加密方式。当认证通过，服务器端响应200状态码之后，浏览器会保存用户名和密码口令，在后续的请求中都携带式Authorization信息。
        Basic认证有太多的缺点，它虽然经过Base64加密后在网络中传送，但是这近乎于明文，十分危险，一般只有在HTTPS的情况下才会使用。不过Basic认证的支持范围十分广泛，几乎所有的浏览器都支持它。

        为了改进Basic认证，RFC 2069规范提出了摘要访问认证，它加入了服务器端随机数来保护认证过程
2. 数据上传
    * 通过报头的Transfer-Encoding或Content-Length即可判断请求中是否带有内容

        ```javascript
        function hasBody (req) {
            return 'transfer-encoding' in req.headers || 'content-length' in req.headers
        }
        ```

    * 表单数据

        ```html
        <form action="/upload" method="post">
            <label for="username">Username:</label> <input type="text" name="username" id="username" />
            <br />
            <input type="submit" name="submit" value="Submit" />
        </form>
        ```

        * Content-Type: application/x-www-form-urlencode
        * 报文体内容跟查询字符串相同：foo=bar&baz=val

        ```javascript
        var handle = function (req, res) {
            if (req.headers['content-type'] === 'application/x-www-form-urlencoded') {
                req.body = querystring.parse(req.rawBody)
            }
            todo(req, res)
        }
        ```

    * JSON
        * Content-Type: application/json; charset=utf-8

        ```javascript
        var mime = function (req) {
            var str = req.headers['content-type'] || ''
            return str.split(';')[0]
        }

        var handle = function (req, res) {
            if (mime(req) === 'application/json') {
                try {
                    req.body = JSON.parse(req.rawBody)
                } catch (e) {
                    res.writeHead(400)
                    res.end('Invaild JSON')
                    return
                }
            }
            todo(req, res)
        }
        ```

    * XML
        * Content-Type: application/xml; charset=utf-8

        ```javascript
        var xml2js = require('xml2js')

        var handle = function (req, res) {
            if (mime(req) === 'application/xml') {
                xml2js.parseString(req.rawBody, function (err, xml) {
                    if (err) {
                        res.writeHead(400)
                        res.end('Invaild XML')
                        return
                    }
                    req.body = xml
                    todo(req, res)
                })
            }
        }
        ```

    * 附件上传

        ```html
        <form action="/upload" method="post" enctype="multipart/form-data">
            <label for="username">Username:</label> <input type="text" name="username" id="username" />
            <label for="file">Filename:</label> <input type="file" name="file" id="file"/>
            <input type="submit" name="submit" value="Submit" />
        </form>
        ```

        浏览器在遇到multipart/form-data表单提交时，构造的请求报文与普通表单完全不同。首先它的报头中最为特殊的如下所示：

        ```javascript
        Content-Type: multipart/form-data; boundary=AaB03x
        Content-Legnth: 18231
        ```

        它代表本次提交的内容是由多部分构成的，其中的boundary=AaB03x指定的是每部分内容的分界符，AaB03x是随机生成的一段字符串，报文体的内容将通过在它前面添加--进行分科，报文结束时在它前后都加上--表示结束。另外，Content-Length的值必须确保是报文体的长度。

        一旦我们知晓报文是如何构成的，那么解析它就变得十分容易。值得注意的一点是，由于是文件上传，那么像普通表单、JSON或XML那样先接受内容再解析的方式将变得不可接受。接收未知的数据量时，我们需要十分谨慎，如下所示：

        ```javascript
        function (req, res) {
            if (hasBody(req)) {
                var done = function () {
                    handle(req, res)
                }

                if (mime(req) === 'application/json') {
                    parseJSON(req, done)
                } else if (mime(req) === 'application/xml') {
                    parseXML(req, done)
                } else if (mime(req) === 'multipart/form-data') {
                    parseMultipart(req, done)
                }
            } else {
                handle(req, res)
            }
        }
        ```

        这里我们将req这个流对象直接交给对应的解析方法，由解析方法自行处理上传的内容，或接收内容并保存在内存中，或流式处理掉。

        这里要介绍的模块是formidable。它基于流式处理解析报文，将接收到的文件写入到系统的临时文件夹中，并返回对应的路径，如下所示：

        ```javascript
        var formidable = require('formidable')

        function parseMultipart (req, res) {
            if (hasBody(req)) {
                if (mime(req) === 'multipart/form-data') {
                    var form = new formidable.IncomingForm()

                    form.parse(req, function (err, fields, files) {
                        req.body = fields
                        req.files = files
                        handle(req, res)
                    })
                } else {
                    handle(req, res)
                }
            }
        }
        ```

3. 数据上传与安全
    * 内存限制
        在解析表单、JSON和XML部分，我们采取的策略是先保存用户提交的所有数据，然后再解析处理，最后才传递给业务逻辑。这种策略存在潜在的问题是，它仅仅适合数据量小的提交请求，一旦数据量过大，将发生内存被占光的情况。攻击者通过客户端能够十分容易地模拟伪造大量数据，如果攻击者每次提交1MB的内容，那么只要并发请求数量一大，内存就会很快地被吃光。

        要解决这个问题主要有两个方案：
        * 限制上传内容的大小，一旦超过限制，停止接收数据，并响应400状态码
        * 通过流式解析，将数据流导向到磁盘中，Node只保留文件路径等小数据
        流式处理在上文的文件上传中已经有所体现，这里介绍一下Connect中采用的上传数据量的限制方式，如下所示：

        ```javascript
        var bytes = 1024

        function (req, res) {
            var received = 0
            var len = req.headers['content-length'] ? parseInt(req.headers['content-length'], 10) : null

            // 如果内容超过长度限制，返回请求实体过长的状态码
            if (len && len > bytes) {
                res.writeHead(413)
                res.end()
                return
            }

            // limit
            req.on('data', function (chunk) {
                received += chunk.length

                if (received > bytes) {
                    // 停止接收数据，触发end()
                    req.destroy()
                }
            })

            handle(req, res)
        }
        ```

    * CSRF
        CSRF的全称是Cross-Site Request Forgery，中文意思是跨站请求伪造，攻击者引诱某个domain_a的登录用户访domain_b的网站，在domain_b的网站中请求domain_a的资源会把domain_a的Cookie发送到服务器，尽管这个请求时来自domain_b的，但是服务器并不知情，用户也不知情。
4. 路由解析
    * 文件路径型
        * 静态文件：URL的路径与网站目录的路径一致，无须转换。处理过程将请求路径对应的文件发送给客户端即可。
        * 动态文件：Web服务器根据URL路径找到对应的文件，如/index.asp或/index.php。Web服务器根据文件名后缀去寻找脚本的解析器，并传入HTTP请求的上下文。解析器执行脚本，并输出响应报文，达到完成服务的目的。现今大多数的服务器都很智能地根据后缀同时服务动态和静态文件。这种方式在Node中不太常见，主要原因是文件的后缀都是.js，分不清是后端脚本，还是前端脚本，这可不是什么好的设计。而且Node中Web服务器与应用业务脚本是一体的，无须按这种方式实现。
    * MVC
        MVC模型的主要思想是将业务逻辑按职责分离，主要分为以下几种：
        * 控制器（Controller)，一组行为的集合
        * 模型（Model），数据相关的操作和封装
        * 视图（View)，视图的渲染
        这是目前最为经典的分层模式，大致而言，它的工作模式如下说明：
        * 路由解析，根据URL寻找到对应的控制器和行为
        * 行为调用相关的模型，进行数据操作
        * 数据操作结束后，调用视图和相关数据进行页面渲染，输出到客户端
        路由映射方法：
        * 手工映射
            * 优点：手工映射除了需要手工配置路由较为原始外，它对URL的要求十分灵活，几乎没有格式上的限制
            * 缺点：如果项目较大，路由映射的数量也会很多。从前端路径到具体的控制文件，需要查阅才能定位到实际代码的位置
        * 自然映射：
            * 优点：路由按照一种约定的方式自然而然地实现了路由，无须去维护路由映射
            * 缺点：如果URL变动，它的文件也需要发生变动
    * RESTful
        REST的全称是Representational State Transfer，中文含义为表现层状态转化。符合REST规范的设计，我们称为RESTful设计。它的设计哲学主要将服务器端提供的内容实体看做一个资源，并表现在URL上。

        比如一个用户的地址如下所示：

        ```javascript
        /users/jacksontian
        ```

        这个地址代表了一个资源，对这个资源的操作，主要体现在HTTP请求方法上，不是体现在URL上。过去我们队用户的增删改查或许是如下这样设计URL的：

        ```javascript
        POST /user/add?username=jacksontian
        GET /user/remove?username=jacksontian
        POST /user/update?username=jacksontian
        GET /user/get?username=jacksontian
        ```

        操作行为主要体现在行为上，主要使用的请求方法是POST和GET。在RESTful设计中，它是如下这样的：

        ```javascript
        POST /user/jacksontian
        DELETE /user/jacksontian
        PUT /user/jacksontian
        GET /user/jacksontian
        ```

        它将DELETE和PUT请求方法引入设计中，参与资源的操作和更改资源的状态

        在RESTful设计中，资源的具体格式由请求报头中Accept字段和服务器端的支持情况来决定。如果客户端同时接受JSON和XML格式的响应，那么它的Accept字段值是如下这样的：

        ```javascript
        Accept: application/json,application/xml
        ```

        在响应报文中，通过Content-Type告知客户端是什么格式

        所以REST的设计就是，通过URL设计资源、请求方法定义资源的操作，通过Accept决定资源的表现形式
5. （中间件的具体实现请查看8.4）中间件：对于Web应用的各种基础功能，我们通过中间件来完成，每个中间件处理掉相对简单的逻辑，最终汇成强大的基础框架
    * 异常处理
    * 中间件与性能
        * 编写高效的中间件
            * 使用高效的方法。必要时通过jsperf.com测试基准性能。
            * 缓存需要重复计算的结果（需要控制缓存用量）
            * 避免不必要的计算。比如HTTP报文体的解析，对于GET方法完全不需要
        * 合理使用路由
6. 页面渲染
    * 内容响应：内容响应的过程中，响应报头中的Content-*字段十分重要
        * MIME：浏览器正式通过不同的Content-Type的值来决定采用不同的渲染方式，这个值我们简称为MIME值。MIME的全称是Multipurpose Internet Mail Extensions。不同的文件类型具有不同的MIME值，为了方便获知文件的MIME值，社区有专有的mime模块可以用来判断文件类型。
    * 附件下载
        * Content-Disposition: attachment; filename="filename.ext"；告知客户端将报文数据作为可下载的附件
        * Content-Disposition: inline；告知客户端将报文数据当做即使浏览的内容
    * 响应JSON

        ```javascript
        res.json = function (json) {
            res.setHeader('Content-Type', 'application/json')
            res.writeHead(200)
            res.end(JSON.stringify(json))
        }
        ```

    * 响应跳转

        ```javascript
        res.redirect = function (url) {
            res.setHeader('Location', url)
            res.writeHead(302)
            res.end('Redirect to' + url)
        }
        ```

7. 视图渲染
8. BigPipe：将页面分割成多个部分，先向用户输出没有数据的布局（框架），将每个部分逐步输出到前端，再最终渲染填充框架，完成整个网页的渲染。这个过程中需要前端JS的参与，它负责将后续输出的数据渲染到页面上

## 第九章 玩转进程

1. Node存在的问题
    * 如何充分利用多核CPU服务器：如今CPU基本均是多核的，真正的服务器（非VPS）往往还有多个CPU。而单进程单线程的结构只能利用一个核
    * 如何保证进程的健壮性核稳定性：由于Node执行在单线程上，一旦单线程上抛出的异常没有被捕获，将会引起整个进程的崩溃
2. 多进程架构
    * Master-Worker模式：又称为主从模式，在这种模式中进程分为两种：主进程和工作进程。这是典型的分布式架构中用于并行处理业务的模式，具备较好的可伸缩性和稳定性。主进程不负责具体的业务处理，而是负责调度和管理工作进程，它是趋向于稳定的。工作进程负责具体的业务助理。
    * 创建子进程
        * spawn()：启动一个子进程来执行命令
        * exec()：启动一个子进程来执行命令，与spawn()不同的是其接口不同，它由一个回调函数获知子进程的状况
        * execFIle()：启动一个子进程来执行科执行文件
        * fork()：与spawn()类似，不同点在于它创建Node的子进程只需指定要执行的JS文件模块即可

        spawn()与exec()、execFile()不同的是，后两者创建时可以指定timeout属性设置超时时间，一旦创建的进程允许超过设定的时间将会被杀死。

        |类型|回调/异常|进程类型|执行类型|可设置超时|
        |spawn()|x|任意|命令|x|
        |exec()|✔️|任意|命令|✔️|
        |execFile()|✔️|任意|可执行文件|✔️|
        |fork()|x|Node|JS文件|x|

        这里的可执行文件是指可以直接执行的文件，如果是JS文件通过execFile()运行，它的首行内容必须添加如下代码：

        ```javascript
        #!/usr/bin/env node
        ```

        尽管4种创建子进程的方式有些差别，但事实上后面3种方法都是spawn()的延伸应用
    * 进程间通信
        * 通过fork()或者其他API，创建子进程之后，为了实现父子进程之间的通信，父进程与子进程之间将会创建IPC通道。通过IPC通道，父子进程之间才能通过message和send()传递消息

            ```javascript
            // parent.js
            var cp = require('child_process')
            var n = cp.fork(__dirname + '/sub.js')

            n.on('message', function (m) {
                console.log('Parent got message:', m)
            })

            n.send({ hello: 'world' })

            // sub.js
            process.on('message'， function (m) {
                console.log('Child got message:', m)
            })

            process.send({ foo: 'bar' })
            ```

        * 进程间通信原理

            IPC的全称是Inter-Process Communication，即进程间通信。实现进程间通信的技术有很多，如命名管道、匿名管道、socket、信号量、共享内存、消息队列、Domain Socket等。Node中实现IPC通道的是管道（pipe）技术。但此管道非彼管道，在Node中管道是个抽象层面的称呼，具体细节实现由libuv提供，在Windows下由命名管道（named pipe）实现，*nix系统则采用Unix Domain Socket实现。

            父进程在实际创建子进程之前，会创建IPC通道并监听它，然后才真正创建出子进程，并通过环境变量（NODE_CHANNEL_FD）告诉子进程这个IPC通道的文件描述符。子进程在启动的过程中，根据文件描述符去连接这个已存在的IPC通道，从而完成父子进程的连接。

            建立连接之后的父子进程就可以自由地通信了。由于IPC通道是用命名管道或Domain Socket创建的，它们与网络socket的行为比较类似，属于双向通信。在Node中，IPC通道被抽象为Stream对象，在调用send()发送数据（类似于write()）接收到的消息会通过message事件（类似于data）触发给应用层。

            ***
            只有启动的子进程是Node进程时，子进程才会根据环境变量去连接IPC通道，对于其他类型的子进程则无法实现进程间通信，除非其他进程也按约定去连接这个已经创建好的IPC通道。
            ***
        * 句柄传递
            通过代理，主进程对外接收所有的网络请求，再将这些请求分别代理到不同的端口的进程上。这样，可以避免端口不能重复监听的问题，甚至可以在代理进程上做适当的负载均衡，使得每个子进程可以较为均衡地执行任务。由于进程每接收到一个连接，将会用掉一个文件描述符，因此代理方案中客户端连接到代理进程，代理进程连接到工作进程的过程需要用掉两个文件描述符。操作系统的文件描述符是有限的，代理方案浪费掉一倍数量的文件描述符的做法影响了系统的扩展能力。

            为了解决上述这样的问题，Node引入了进程间发送句柄的功能。send()方法除了能通过IPC发送数据外，还能发送句柄，第二个可选参数就是句柄，如下所示：

            ```javascript
            child.send(message, [sendHandle])
            ```

            那什么是句柄？句柄是一种可以用来标识资源的引用，它的内部包含了指向对象的文件描述符。比如句柄可以用来标识一个服务器端socket对象、一个客户端socket对象、一个UDP套接字、一个管道等。

            发送句柄意味着什么？在前一个问题中，我们可以去掉代理这种方案，使主进程接收到socket请求后，将这个socket直接发送给工作进程，而不是重新与工作进程之间建立新的socket连接来转发数据。文件描述符浪费的问题可以通过这样的方式轻松解决。

            ```javascript
            // parent.js
            var cp = require('child_process')
            var child1 = cp.fork('child.js')
            var child2 = cp.fork('child.j2')

            var server = require('net').createServer()
            server.listen(1337, function () {
                child.send('server', server)
                child.send('server', server)
                // 关掉
                server.close()
            })

            // child.js
            var http = require('http')
            var server = http.createServer(function (req, res) {
                res.writeHead(200, { 'Content-Type': 'text/plain' })
                res.end('handled by child, pid is ' + process.id + '\n')
            })

            process.on('message', function (m, tcp) {
                if (m === 'server') {
                    tcp.on('connection', function (socket) {
                        server.emit('connection', socket)
                    })
                }
            })
            ```

            * 句柄发送与还原

                上文介绍的虽然是句柄发送，但是仔细看看，句柄发送跟我们直接将服务器对象发送给子进程有没有差别？它是否真的将服务器对象发送给了子进程？为什么它可以发送到多个子进程中？发送给子进程为什么父进程中还存在这个对象？

                目前子进程对象send()方法可以发送的句柄类型包括如下几种：
                * net.Socket。TCP套接字。
                * net.Server。TCP服务器，任意建立在TCP服务上的应用层服务都可以享受到它带来的好处。
                * net.Native。C++层面的TCP套接字或IPC管道。
                * dgram.Socket。UDP套接字。
                * dgram.Native。C++层面的UDP套接字。

                send()方法在将消息发送到IPC管道前，将消息组装成两个对象，一个参数是handle，另一个是message。message参数如下所示：

                ```javascript
                {
                    cmd: 'NODE_HANDLE',
                    type: 'net.Server',
                    msg: message
                }
                ```

                发送到IPC管道中的实际上是我们要发送的句柄文件描述符，文件描述符实际上是一个整数值。这个message对象在写入到IPC管道时也会通过JSON.stringify()进行序列化。所以最终发送到IPC通道中的信息都是字符串，send()方法能发送消息和句柄并不意味着它能发送任意对象。

                连接了IPC通道的子进程可以读取到父进程发来的消息，将字符串通过JSON.parse()解析还原为对象后，才触发message事件将消息体传递给应用层使用。在这个过程中，消息对象还要被进行过滤处理，message.cm的值如果以NODE_为前缀，它将响应一个内部事件internalMessage。如果message.cmd的值为NODE_HANDLE，它将取出message.type值和得到的文件描述符一起还原出一个对应的对象。

            * 端口共同监听

                在了解了句柄传递背后的原理后，我们继续探究为何通过发送句柄后，多个进程可以监听到相同的端口而不引起EADDRINUSE异常。其答案也很简单，我们独立启动的进程中，TCP服务器端socket套接字的文件描述符并不相同，导致监听到相同的端口时会抛出异常。

                Node底层对每个端口监听都设置了SO_REUSEADDR选项，这个选项的涵义是不同进程可以就相同的网卡和端口进行监听，这个服务器端套接字可以被不同的进程复用

                由于独立启动的进程互相之间并不知道文件描述符，所以监听相同端口时会失败。但对于send()发送的句柄还原出来的服务而言，它们的文件描述符是相同的，所以监听相同的端口不会引起异常。

                多个应用监听相同的端口时，文件描述符同一时间只能被某个进程所用。换言之就是网络请求向服务器发送时，只有一个幸运的进程能够抢到连接，也就是说只有它能为这个请求进行服务。这些进程服务是抢占式的。

3. 集群稳定之路
    * 问题
        * 性能问题
        * 多个工作进程的存活状态管理
        * 工作进程的平滑重启
        * 配置或者静态数据的动态重新载入
        * 其他细节
    * 进程事件
        * error：当子进程无法被复制创建、无法被杀死、无法发送消息时会触发该事件。
        * exit：子进程退出时触发该事件，子进程如果是正常退出，这个事件的第一个参数为退出码，否则为null。如果进程是通过kill()方法杀死的，会得到第二个参数，它表示杀死进程时的信号。
        * close：在子进程的标准输入输出流中止时触发该事件，参数与exit相同。
        * disconnect：在父进程或子进程中调用disconnect()方法式触发该事件，在调用该方法时将关闭监听IPC通道。
    * 自动重启：

        一旦有未捕获的异常出现，工作进程就会立即停止接收新的连接；当所有连接断开后，退出进程。主进程在侦听到工作进程的exit后，将会立即启动新的进程服务，以此保证整个集群中总是有进程在为用户服务的。

        * 自杀信号
            上述过程存在的问题是要等到已有的连接断开后进程才退出，在极端的情况下，所有工作进程都停止接收新的连接，全处在等待退出的状态。但在等到进程完全退出在重启的过程中，所有新来的请求可能存在没有工作进程为新用户服务的情景，这回丢掉大部分请求。

            为此需要改进这个过程，不能等到工作进程退出后才重启新的工作进程。当然也不能暴力退出进程，因为这样会导致已连接的用户之间断开。于是我们在退出的流程中增加一个自杀（suicide）信号。工作进程在得知要退出时，向主进程发送一个自杀信号，然后才停止接收新的连接，当所有连接断开后才退出。主进程在接收到自杀信号后，立即创建新的工作进程服务。

            这里存在问题的是有可能我们的连接是长连接，不是HTTP服务的这种短连接，等待长连接断开可能需要较久的时间。为此为已有的连接的断开设置一个超时时间是必要的。

            进程中如果出现未能捕获的异常，就意味着有那么一段代码在健壮性上是不合格的。为此退出进程前，通过日志记录下问题所在是必须要做的事情，它可以帮我们很好地定位和追踪代码异常出现的位置。

        * 限量重启
            通过自杀信号告知主进程可以使得新连接总是有进程服务，但是依然还是有极端的情况。工作进程不能无限制地被重启，如果启动的过程中就发生了错误，或者启动后接到连接就收到错误，会导致工作进程被频繁重启，这种频繁重启不属于我们捕捉未知异常的情况，因为这种短时间内频繁重启已经不符合预期的设置，极有可能是程序编写的错误。

            为了消除这种无意义的重启，在满足一定规则的限制下，不应当反复重启。比如在单位时间内规定只能重启多少次，超过限制就触发giveup事件，告知放弃重启工作进程这个重要事件。

    * 负载均衡
        Node默认提供的机制是采用操作系统的抢占式策略。所谓的抢占式就是在一堆工作进程中，闲着的进程对到来的请求进行争抢，谁抢到谁服务。

        一般而言，这种抢占式策略对大家是公平的，各个进程可以根据自己的繁忙度来进行抢占。但是对于Node而言，需要分清的是它的繁忙是有CPU、I/O两个部分构成的，影响抢占的是CPU的繁忙度。对不同的业务，可能存在I/O繁忙，而CPU较为空闲的情况，这可能造成某个进程能够抢到较多的请求，形成负载不均衡的情况。

        为此Node在V0.11中提供了一种新的策略使得负载均衡更合理，这种新的策略叫Round-Robin，又叫轮叫调度。轮叫调度的工作方式是由主进程接受连接，将其以此分发给工作的进程。分发的策略是在N个工作进程中，每次选择第i=(i + 1) mod n个进程来发送连接。

    * 状态共享
        解决数据共享最直接、简单的方式就是通过第三方来进行数据存储，比如将数据存放到数据库、磁盘文件、缓存服务（如Redis)中，所有工作进程启动时将其读取进内存中。但这种方式存在的问题是如果数据发生改变，还需要一种机制通知到各个子进程，使得它们的内部状态也得到更新。

        实现状态同步的机制有两种：
        * 各个子进程去向第三方进行定时轮询
        * 创建一个通知进程，这个进程设计为值进行轮询和通知，不处理任何业务逻辑。进程在启动时从通知服务处除了读取第一次数据外，还将进程信息注册到通知服务处。一旦轮询发现有数据更新后，根据注册信息，将更新后的数据发送给工作进程。

4. Cluster模块

    ```javascript
    var cluster = require('cluster')

    cluster.setupMaster({
        exec: 'workter.js'
    })

    var cpus = require('os').cpus()
    for (var i = 0; i < cpus.length; i++) {
        cluster.fork()
    }
    ```

    执行上述代码将会得到与前文创建子进程集群的效果相同。就官方的文档而言，它更喜欢如下的形式作为示例：

    ```javascript
    var cluster = require('cluster')
    var http = require('http')
    var numCPUs = require('os').cpus().length

    if (cluster.isMaster) {
        // Fork workers
        for (var i = 0; i < numCPUs; i++) {
            cluster.fork()
        }

        cluster.on('exit', function (worker, code, signal) {
            console.log('worker' + worker.process.pid + ' died')
        })
    } else {
        // Workers can share any TCP connection
        http.createServer(function (req, res) {
            res.writeHead(200)
            res.end('hello world\n')
        }).listen(8000)
    }
    ```

    在进程中判断是主进程还是工作进程，主要取决于环境变量中是否有NODE_UNIQUE_ID，如下所示：

    ```javascript
    cluster.isWorker = ('NODE_UNIQUE_ID' in process.env)
    cluster.isMaster - (cluster.isWorker === false)
    ```

    * Cluster工作原理

    事实上cluster模块就是child_process和net模块的组合应用。cluster启动时，它会在内部启动TCP服务器，在cluster.fork()子进程时，将这个TCP服务器端socket的文件描述符发送给工作进程。如果进程是通过cluster.fork()复制出来的，那么它的环境变量就存在NODE_UNIQUE_ID，如果进程中存在listen()侦听网络端口的调用，它们将拿到该文件描述符，通过SO_REUSEADDR端口重用，从而实现多个子进程共享端口。对于普通方式启动的进程，则不存在文件描述符传递共享等事情。

    在cluster内部隐式创建TCP服务器的方式对使用者来说十分透明，但也正是这种方式使得它无法入直接使用child_process那样灵活。在cluster模块应用中，一个主进程只能管理一组工作进程。

    对于自行通过child_process来操作时，则可以更灵活地控制工作进程，甚至控制多组工作进程。其原因在于自行通过child_process操作子进程时，可以隐式地创建多个TCP服务器，使得子进程可以共享多个的服务器端socket。

    * Cluster事件
        * fork：复制一个工作进程后触发该事件。
        * online：复制好一个工作进程后，工作进程主动发送一条online消息给主进程，主进程收到消息后，触发该事件。
        * listening：工作进程中调用listen()（共享了服务端Socket）后，发送一条listening消息给主进程，主进程收到消息后，触发该事件
        * exit：有工作进程退出时触发该事件。
        * setup：cluster.setupMaster()执行后触发该事件

## 第十章 测试

1. 单元测试
    * 编写可测试代码有以下几个原则可以遵循
        * 单一职责
        * 接口抽象
        * 层次分离
    * 单元测试介绍
        * 断言
            在程序设计中，断言（assertion）是一种放在程序中的一阶逻辑（如一个结果为真或是假的逻辑判断式），目的是为了标识程序开发者预期的结果——当程序运行到断言的位置时，对应的断言应该为真。若断言不为真，程序会中止运行，并出现错误信息。

            assert模块
            * ok()：判断结果是否为真。
            * equal()：判断实际值与期望值是否相等。
            * notEqual()：判断实际值与期望值是否不相等。
            * deepEqual()：判断实际值与期望值是否深度相等（对象或数组的元素是否相等）。
            * notDeepEqual()：判断实际值与期望值是否不深度相等。
            * strictEqual()：判断实际值与期望值是否严格相等（相当于===）。
            * notStrictEqual()：判断实际值与期望值是否不严格相等（相当于!==)。
            * throws()：判断代码块是否抛出异常。
            * doesNotThrow()：判断代码块是否没有抛出异常。
            * ifError()：判断实际值是否为一个假值（null、undefined、0、''、false），如果实际值为真值，将会抛出异常。
        * 测试框架：mocha
            * 测试风格：我们将测试用例的不同组织方式称为测试风格，现今流行的单元测试风格主要有TDD（测试驱动开发）和BDD（行为驱动开发）两种，他们的差别如下：
                * 关注点不同：TDD关注所有功能是否被正确实现，每一个功能都具备对应的测试用例；BDD关注整体行为是否符合预期，适合自顶向下的设计方式。
                * 表达方式不同：TDD的表述方式偏向于功能说明书的风格；BDD的表述方式更接近于自然语言的习惯。

                ```javascript
                // BDD
                describe('Array', function () {
                    // 提供了before、after、beforeEach、afterEach钩子方法
                    before (function () {
                        // ...
                    })

                    describe('#indexOf()', function () {
                        it('should return -1 when not present', function () {
                            [1, 2, 3].indexOf(4).should.equal(-1)
                        })
                    })
                })

                // TDD
                suite('Array', function () {
                    // 提供了setup、teardown钩子方法
                    setup (function () {
                        // ...
                    })

                    suite('#indexOf()', function () {
                        test('should return -1 when not present', function () {
                            assert.equal(-1, [1, 2, 3].indexOf(4))
                        })
                    })
                })
                ```

            * 测试报告
            * 测试代码的文件组织：测试代码存在于test目录中
            * 测试用例
                一个测试用例中包含至少一个断言。示例代码如下：

                ```javascript
                describe('#indexOf()', function () {
                    it('should return -1 when not present', function () {
                        [1, 2, 3].indexOf(4).should.equal(-1)
                    })

                    it('should return index when present', function () {
                        [1, 2, 3].indexOf(1).should.equal(0)
                        [1, 2, 3].indexOf(2).should.equal(1)
                        [1, 2, 3].indexOf(3).should.equal(2)
                    })
                })
                ```

                测试用例最少需要通过正向测试和反向测试来保证测试对功能的覆盖，这是最基本的测试用例。对于Node而言，不仅有这样简单的方法调用，还有异步代码和超时设置需要关注。
                * 异步测试
                    由于Node环境的特殊性，异步调用非常常见，这也带来了异步代码在测试方面的跳转。在其他典型编程语言中，如Java、Ruby、Python，代码大多是同步执行的，所以测试用例基本上只要包含一些断言检查返回值即可。但是在Node中，检查方法的返回值毫无意义，并且不知道回调函数具体何时调用结束，这将导致我们在对异步调用进行测试时，无法调度后续测试用例的执行。

                    所幸，mocha解决了这个问题。一下为fs模块中readFile的测试用例

                    ```javascript
                    it('fs.readFile should be ok', function (done) {
                        fs.readFile('file_path', 'utf-8', function (err, data) {
                            should.not.exist(err)
                            done()
                        })
                    })
                    ```

                    在上述代码中，测试用例方法it()接受两个参数；用例标题和回调函数。通过检查这个回调函数的形参长度（fn.length）来判断这个用例是否是异步调用，如果是异步调用，在执行测试用例时，会将一个函数done()注入为实参，测试代码需要主动调用这个函数通知测试框架当前测试用例执行完成，然后测试框架才进行下一个测试用例的执行。
                * 超时设置
                    mocha给所有涉及异步的测试用例添加了超时限制，如果一个用例的执行时间超过了预期时间，将会记录下一个超时错误，然后执行下一个测试用例。

                    mocha的默认超时时间为2000毫秒。一般情况下，通过Mocha -t &lt;ms&gt;设置所有用例的超时时间。若需更细粒度地设置超时时间，可以在测试用例it中调用this.timeout(ms)实现对单个用例的特殊设置，示例代码如下：

                    ```javascript
                    it('should take less than 500ms', function (done) {
                        this.timeout(500)
                        setTimeout(done, 300)
                    })
                    ```

                    也可以在描述describe中调用this.timeout(ms)设置描述下当前层级的所有用例：

                    ```javascript
                    describe('a suit of tests', function () {
                        this.timeout(500)
                        it('should take less than 500ms', function (done) {
                            setTimeout(done, 300)
                        })

                        it('should take less than 500ms as well', function (done) {
                            setTimeout(done, 200)
                        })
                    })
                    ```

            * 测试覆盖率
                通过统计每一行代码是否执行来得知测试用例对源码的覆盖率

                blanket模块

                ```javascript
                // 只需在所有测试用例之前通过--require选项引入它即可
                mocha --require blanket -R html-cov > coverage.html

                // 在包描述文件(package.json)文件中配置scripts节点，pattern属性用以匹配需要编译的文件
                "scripts": {
                    "blanket": {
                        "pattern": "eventproxy/lib"
                    }
                }
                ```

            * mock
                前面提到开发者常常会遗漏掉一些异常案例，其中想当一部分原因在于异常的情况较难实现。大多异常与输入数据并无绝对的关系，比如数据库的异步调用，除了输入异常外，还有可能是网络异常、权限异常等非输入数据相关的情况，这相对难以模拟。

                以下面代码为例，文件系统的异常时绝对不容易呈现的，为了测试代码的健壮性而专程调节磁盘上的权限等，成本略高：

                ```javascript
                exports.getContent = function (filename) {
                    try {
                        return fs.readFileSync(filename, 'utf-8')
                    } catch (e) {
                        return ''
                    }
                }
                ```

                为了解决这个问题，我们通过伪造fs.readFileSync()方法抛出错误来触发异常。同时为了保证该测试用例不影响其余用例，我们需要在执行完后还原它。为此，前面提到的before()和after()钩子函数派上了用场，相关代码如下：

                ```javascript
                describe('getContent', function () {
                    var _readFileSync

                    before(function () {
                        _readFileSync = fs.readFileSync
                        fs.readFileSync = function (filename, encoding) {
                            throw new Error('mock readFileSync error')
                        }
                    })

                    // it()

                    after(function () {
                        fs.readFileSync = _readFileSync
                    })
                })
                ```

                我们在执行测试用例前将引用替换掉，执行结束后还原它。如果每个测试用例执行前后都要进行设置和还原，就使用beforeEach()和afterEach()这两个钩子函数。

                由于mock的过程比较烦琐，这里推荐一个模块来解决此事——muk，示例代码如下：

                ```javascript
                var fs = require('fs')
                var muk = require('muk')

                before(function () {
                    muk(fs. 'readFileSync', function (path, encoding) {
                        throw new Error('mock readFileSync error')
                    })
                })

                // it()

                after(function () {
                    muk.restore()
                })
                ```

                值得注意的一点是，对于异步方法的模拟，需要十分小心是否将异步方法模拟为同步

                ```javascript
                // error
                fs.readFile = function (filename, encoding, callback) {
                    callback(new Error('mock readFile error'))
                }

                // good
                fs.readFile = function (filename, encoding, callback) {
                    process.nextTick(function () {
                        callback(new Error('mock readFile error'))
                    })
                }
                ```

            * 私有方法的测试
                对于Node而言，又一个难点会出现在单元测试的过程中，那就是私有方法的测试，这在第2章中介绍过。只有挂载在exports或module.exports上的变量或方法才可以被外部通过require引入访问，其余方法只能在模块内部被调用和访问。

                rewrite模块提供了一种巧妙的方式实现对私有方法的访问

                ```javascript
                // 源代码
                var limit = function (num) {
                    return num < 0 ? 0 : num
                }

                // 测试用例
                it('limit should return success', function () {
                    var lib = rewrite('../lib/index.js')
                    var limit = lib.__get__('limit')
                    litmit(10).should.be.equal(10)
                })
                ```

                rewrite的诀窍在于它引入文件时，像require一样对原始文件做了一定的手脚。除了添加(function(exports, require, module, __filename, __dirname){)和});的头尾包装外，它还注入了部分代码，具体如下所示：

                ```javascript
                (function (exports, require, module, __filename, __dirname) {
                    var method = function () {}
                    exports.__set__ = function (name, value) {
                        eval(name ' = ' value.toString())
                    }

                    exports.__get__ = function (name) {
                        return eval(name)
                    }
                })
                ```

                每一个被rewrite引入的模块都有__set__()和__get__()方法。它巧妙利用了闭包的诀窍，在eval()执行时，实现了对模块内部局部变量的访问，从而可以将局部变量导出给测试用例调用执行。
    * 工程化和自动化
2. 性能测试
    * 基准测试
        基准测试要统计的就是在多少时间内执行了多少次某个方法。为了增强可比性，一般会以次数作为参照物，然后比较时间，以此来判别性能的差距。

        这里介绍benchmark这个模块是如何组织基准测试的，相关代码如下：

        ```javascript
        var Benchmark = require('benchmark')

        var suite = new Benchmark.Suite()

        var arr = [0, 1, 2, 3, 5, 6]
        suite.add('nativeMap', function () {
            return arr.map(callback)
        }).add('customMap', function () {
            var ret = []

            for (var i = 0; i < arr.length; i++) {
                ret.push(callback(arr[i]))
            }
            return ret
        }).on('cycle', function (event) {
            console.log(String(evnet.target))
        }).on('complete', function () {
            console.log('Fastest is ' + this.fileter('fastest').pluck('name'))
        }).run()
        ```

        它通过suite来组织每组测试，在测试套件中调用add()来添加被测试的代码

        执行上述代码，得到的输出结果如下

        ```javascript
        nativeMap x 1,227,341 ops/sec ±1.99%(83 runs sampled)
        customMap x 7,919,649 ops/sec ±0.57%(96 runs sampled)
        Fastest is customMap
        ```

    * 负载测试
    * 压力测试
        除了可以对基本的方法进行基准测试外，通常还会对网络接口进行压力测试以判断网络接口的性能，这在第六章演示过。对网络接口做压力测试需要考查的几个指标有吞吐率、响应时间和并发数，这些指标反映了服务器的并发处理能力。

        最常用的工具是ab、siege、http_load等
    * 基准测试驱动开发
    * 测试数据与业务数据的转换
        假设某个页面每天的访问量为100万。根据实际业务情况，主要访问量大致集中在10个小时以内，那么换算公式就是：

        ```javascript
        QPS = PV / 10h
        ```

        100万的业务访问量换算为QPS，约等于27.7，即服务器需要每秒处理27.7个请求才能胜任业务量

## 第十一章 产品化

1. 项目工程化
    * 目录结构
    * 构建工具
    * 代码审查
2. 部署流程
    * 部署环境
    * 部署操作
3. 性能
    * 动静分离：将动态请求和静态请求分离，使服务器专注在动态服务方面，专业的CDN会将静态文件与用户尽可能靠近，同时能够有更精确和高效的缓存机制。
    * 启用缓存：提升性能其实差不多只有两个途径，一是提升服务的速度，二是避免不必要的计算。前者提升的性能在海量流量面前终有瓶颈，但后者却能够在访问量越大时收益越多。避免不要的计算，应用场景做多的就是缓存。
    * 多进程架构：通过多进程架构，不仅可以充分利用多核CPU，更是可以建立机制让Node进程更加健壮，，以保障Web应用持续服务。
    * 读写分离：除了动静分离外，另一个较为重要的分离是读写分离，这主要针对数据库而言。就任意数据库而言，读取的速度远远高于写入的速度。而某些数据库在写入时为了保证数据的一致性，会进行锁表操作，这同时会影响到读取的速度。某些系统为了提升性能，通常会进行数据库的读写分离，将数据库进行主从设计，这样读数据操作不再受到写入的影响。
4. 日志
    * 访问日志：一般用来记录每个客户端对应用的访问
    * 异常日志：通常用来记录那些意外产生的异常错误
        异常日志通常有完善的分级，Node中提供console对象就简单地实现了这几种划分，具体如下所示：
        * console.log：普通日志
        * console.info：普通信息
        * console.warn：警告信息
        * console.error：错误信息
        console模块在具体实现时，log与info方法都将信息输出给标准输出process.stdout，warn与error方法则将信息输出到标准错误process.stderr，而info和error分别是log和warn的别名。下面为它们的实现代码：

        ```javascript
        Console.prototype.log = function () {
            this._stdout.write(util.format.apply(this, arguments) + '\n')
        }

        Console.prototype.info = Console.prototype.log

        Console.prototype.warn = function () {
            this._stderr.write(util.format.apply(this, arguments) + '\n')
        }

        Console.prototype.error = Console.prototype.warn
        ```

        console对象上具有一个Console属性，它是console对象的构造函数。借助这个构造函数，我们可以实现自己的日志对象，相关代码如下：

        ```javascript
        var info = fs.createWriteStream(logdir + '/info.log', {flags: 'a', mode: '0666'})
        var error = fs.createWriteStream(logdir + '/error.log', {flags: 'a', mode: '0666'})

        var logger = new console.Console(info, error)
        ```

        分别调用它的API，日志内容就能各自写入到对应的文件中，相关代码如下：

        ```javascript
        logger.log('Hello world!')
        logger.error('segment fault')
        ```

        有了记录信息的日志API后，开发者需要关心的是要小心捕获每一个异常，在第四章中，我们提到异步调用中回调函数里的异常无法被外部捕获的问题，也提到了异步API编写的规范，每个开发者应当将API内部发生的异常作为第一个实参传递给回调函数。对于回调函数产生的异常，则可以不用过问，交给全局的uncaughtException事件去捕获即可。

        在逐层次的异步API调用中，异常是该传递给调用方还是立即通过日志记录，这是一个需要注意的问题。就通常的API编写而言，尽量不要隐藏错误，不要通过try/catch块将异常捕获，然后隐藏起来不向外部调用者暴露。这对于底层API的设计而言，尤为重要。事实上，日志通常是服务于业务的。建议异常尽量由上层的调用者捕获记录，底层调用或中间层调用中出现的异常只要正常传递给上层的调用方即可。
    * 日志与数据库
        有的开发者对日志可能不太了解，会选择将一些日志写入到数据库中。数据库比日志文件好的地方在于它是结构化数据，可以直接编写SQL语句进行分析，日志文件则需要再加工之后才能分析。但是日志文件与数据库写入在性能上处于两个级别，数据库在写入过程中要经历一系列处理，比如锁表、日志等操作。写日志文件则是直接将数据写到磁盘上。为此，如果有大量的访问，可能会存在写入操作大量排队的状况，数据库的消费速度严重低于生产速度，进而导致内存泄漏等。相比之下，写日志是轻量的方法，将日志分析和日志记录这两个步骤分离开来是较好的选择。日志记录可以在线写，日志分析则可以借助一些工具同步到数据库中，通过离线分析的方式反馈出来。
    * 分割日志：将产生的日志按日期分割
5. 监控报警
    应用的监控主要有两类，一种是业务逻辑型的监控，一种是硬件型的监控。监控主要通过定时采样来进行记录。除此之外，还要对监控的信息设置上限，一旦出现大的波动，就需要发出警报提醒开发者。为了较好地供开发者使用，监控到的信息一般还要通过数据可视化的方式反映出来，以便更直观地查看。

    * 监控
        * 日志监控：通过监控异常日志文件的变动，将新增的异常按异常类型和数量反映出来；对于访问日志的监控也能体现出实际的业务QPS值。观察QPS的表现能够检查业务在时间上的分布。此外，从访问日志中也能实现PV和UV的监控。同QPS值一样，通过对PV/UV的监控，可以很好地知道应用的使用者们的习惯、预知访问高峰等。
        * 响应时间：响应时间也是一个需要监控的点。一旦系统的某个子系统出现异常或者性能瓶颈，将会导致系统的响应时间变长。响应时间可以在Nginx一类的反向代理上监控，也可以通过应用自行产生的访问日志来监控。
        * 进程监控：监控进程一般是检查操作系统中运行的应用进程数，比如对于采用多进程架构的Web应用，就需要检查工作进程的数量，如果低于预估值，就应当发出报警声。
        * 磁盘监控：磁盘监控主要是监控磁盘的用量。由于日志频繁写的缘故，磁盘空间渐渐被用光。一旦磁盘不够用，将会引发系统的各种问题。给磁盘的使用量设置一个上限，一旦磁盘用量超过警戒值，服务器的管理者就应该整理日志或清理磁盘了。
        * 内存监控：监控服务器的内存使用状况，可以检查应用中是否存在内存泄漏的状况。如果内存只升不降，那么铁定存在内存泄漏问题。健康的内存使用应当是有升有降，在访问量大的时候上升，在访问量回落的时候，占用量也随之回落。
        * CPU占用监控：CPU的使用分为用户态、内核态、IOWait等。如果用户态CPU使用率较高，说明服务器上的应用需要大量的CPU开销；如果内核态CPU使用率较高，说明服务器花费大量时间进行进程调度或者系统调用；IOWait使用率则反应的是CPU等待磁盘I/O操作。
        * CPU load监控：CPU load又称CPU平均负载，它用来描述操作系统当前的繁忙程度，可以简单地理解为CPU在单位时间内正在使用和等待使用CPU的平均任务数。它有3个指标，即1分钟的平均负载、5分钟的平均负载、15分钟的平均负载。CPU load过高说明进程数量过多，这在Node中可能体现在用子进程模块反复启动新的进程。
        * I/O负载：I/O负载指的主要是磁盘I/O。反应的是磁盘上的读写情况，对于Node编写的应用，主要是面向网络服务，是故不太可能出现I/O负载过高的情况，大多数的I/O压力来自于数据库。
        * 网络监控：虽然网络流量监控的优先级没有上诉项目那么高，但还是需要对流量进行监控并设置上限值。即便应用突然受到用户的青睐，流量暴涨时也能通过数值感知到网站的宣传是否有效。一旦流量超过警戒值，开发者就应当找出流量增长的原因。对于正常增长，应当评估是否该增加硬件设备来为更多用户提供服务。网路流量监控的两个主要指标是流入流量和流出流量。
        * 应用状态监控：除了这些硬性需要检测的指标外，应用还应当提供一种机制来反馈其自身的状态信息，外部监控将会持续地调用应用的反馈接口来检查它的健康状态。最简单的状态反馈就是给监控响应一个时间戳，监控方检查时间戳是否正常即可。健壮一些的状态响应则是将应用的依赖项的状态打印出来，如数据库连接是否正常、缓存是否正常等。
        * DNS监控：DNS是网络应用的基础，在实际的对外服务的产品中，多数都对域名有依赖。DNS故障导致产品出现大面积影响的事件并不少见。由于DNS服务通常是稳定的，容易让人忽略，但一旦出现故障，就可能是史无前例的故障。对于产品的稳定性，域名DNS状态也需要加入监控。目前国内有一些免费的DNS监控服务，如DNSPod等，可以通过这些监控服务，监控自己的在线应用。

    * 报警
        * 邮件报警：可以调用nodemailer模块来实现邮件的发送
        * 短信或电话报警：
6. 稳定性
    * 多机器：多机器部署应用带来的好处是能利用更多的硬件资源，为更多的请求服务。同时能够在有故障时，继续服务用户请求，保证整体系统的高可用性。但是一旦出现分布式，就需要考虑负载均衡、状态共享和数据一致性问题。
    * 多机房：多机房部署是比多机器部署更高层次的部署，目的是为了解决地理位置给用户访问带来的延迟问题。在容灾方面，机房与机房之间可以互相备份。由于机房与机房之间的网络复杂度再度提升，负载均衡方面需要进一步去统筹规划。
    * 容灾备份：在多机房和多机器的部署结构下，十分容易通过备份的方式进行容灾，任何一台机器或者一个机房停止了服务，都能有其余的服务器来接替新的任务。
7. 异构共存
